{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-21T03:27:43.628313Z",
     "start_time": "2019-07-21T03:27:34.819524Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras import optimizers\n",
    "\n",
    "\n",
    "import sys\n",
    "from collections import Counter \n",
    "import pprint \n",
    "import math\n",
    "import argparse \n",
    "import os\n",
    "import collections\n",
    "import json\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import random\n",
    "import time \n",
    "import pandas as pd\n",
    "import itertools\n",
    "import tensorflow as tf\n",
    "\n",
    "seed_value= 0\n",
    "os.environ['PYTHONHASHSEED']=str(seed_value)\n",
    "random.seed(seed_value)\n",
    "np.random.seed(seed_value)\n",
    "tf.set_random_seed(seed_value)\n",
    "from keras import backend as K\n",
    "session_conf = tf.ConfigProto(intra_op_parallelism_threads=4, inter_op_parallelism_threads=4)\n",
    "sess = tf.Session(graph=tf.get_default_graph(), config=session_conf)\n",
    "K.set_session(sess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/apple/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package words to /Users/apple/nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /Users/apple/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "\n",
    "# funtions to handle labels\n",
    "from utils.handle_labels import get_tag_counts_and_labels\n",
    "from utils.handle_labels import drop_labels\n",
    "from utils.handle_labels import group_labels\n",
    "from utils.handle_labels import categories_count\n",
    "from utils.handle_labels import get_imbalance\n",
    "from utils.handle_labels import label_distribution\n",
    "from utils.handle_labels import number_of_labels\n",
    "from utils.message_preprocess import message_processing\n",
    "# plot untils funcion\n",
    "from utils.plot_utils import pie_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1922, 28)\n",
      "<class 'list'>\n",
      "['Testing', 'Bug fix']\n",
      "Maintenance : 891\n",
      "Feature Add : 330\n",
      "Bug fix : 266\n",
      "Documentation : 237\n",
      "Clean up : 192\n",
      "Refactoring : 111\n",
      "Indentation : 48\n",
      "Token Replace : 40\n",
      "Source Control : 30\n",
      "Cross : 24\n",
      "Legal : 18\n",
      "Debug : 10\n",
      "Module Remove : 6\n",
      "Module Move : 5\n",
      "Rename : 5\n",
      "Versioning : 4\n",
      "Merge : 3\n",
      "Initialization : 2\n",
      "Internationalization : 1\n",
      "Data : 1\n",
      "Module Add : 1\n",
      "1    1625\n",
      "2     226\n",
      "3      35\n",
      "4       7\n",
      "5       3\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corrective : 266\n",
      "Adaptive : 239\n",
      "Perfective : 1130\n",
      "Implementation : 334\n",
      "Non_functional : 70\n",
      "Other : 34\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('data/commit_data_new.csv')\n",
    "print(df.shape)\n",
    "\n",
    "# convert string to list\n",
    "from ast import literal_eval\n",
    "\n",
    "df['categories'] = df['categories'].apply(lambda x: literal_eval(x))\n",
    "print(type(df['categories'].values[0]))\n",
    "print(df['categories'].values[0])\n",
    "df = df.drop(['Unnamed: 0'], axis = 1)\n",
    "df.head()\n",
    "\n",
    "#tags_counts,target_columns = get_tag_counts_and_labels(df)\n",
    "#print(target_columns)\n",
    "\n",
    "# drop testing and build\n",
    "new_df = drop_labels(df, ['Testing', 'Build'])\n",
    "_ , target_col = get_tag_counts_and_labels(new_df)\n",
    "multi_count = number_of_labels(new_df, target_col)\n",
    "\n",
    "def group_labels_new(df, labels_to_group, new_label):\n",
    "    '''\n",
    "    Group some of labels\n",
    "\n",
    "    Args:\n",
    "        df - dataframe\n",
    "        labels_to_group -  List of labels you want to group\n",
    "        new_label -  string - new label name of grouped labels\n",
    "\n",
    "    Returns:\n",
    "        new_df - dataframe after grouped\n",
    "    '''\n",
    "    new_df = df.copy()\n",
    "\n",
    "    # generate new labels by group labels\n",
    "    def create_new_label(row, labels):\n",
    "        new_label = 0  # initialize new label\n",
    "        for label in labels:\n",
    "            if row[label] == 1:\n",
    "                new_label = 1  # if one of labels in grouped labels is 1 the new label is 1\n",
    "        return new_label\n",
    "\n",
    "    new_df[new_label] = df.apply(lambda row: create_new_label(row, labels_to_group), axis=1)\n",
    "\n",
    "    # generate list of new_categories\n",
    "\n",
    "    return new_df\n",
    "\n",
    "new_df = group_labels_new(new_df, ['Bug fix'], 'Corrective')\n",
    "new_df = group_labels_new(new_df, ['Internationalization', 'Documentation','Data'], 'Adaptive')\n",
    "new_df = group_labels_new(new_df, ['Clean up', 'Indentation','Maintenance','Module Move','Module Remove','Refactoring'], 'Perfective')\n",
    "new_df = group_labels_new(new_df, ['Initialization', 'Feature Add','Module Add','Internationalization'], 'Implementation')\n",
    "new_df = group_labels_new(new_df, ['Legal', 'Module Remove','Rename','Token Replace','Merge'], 'Non_functional')\n",
    "new_df = group_labels_new(new_df, ['Cross','Debug'], 'Other')\n",
    "\n",
    "target_col = ['Corrective','Adaptive','Perfective','Implementation','Non_functional','Other']\n",
    "multi_count = categories_count(new_df, target_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corrective : 266\n",
      "Adaptive : 239\n",
      "Perfective : 1130\n",
      "Implementation : 334\n"
     ]
    }
   ],
   "source": [
    "# Drop 'Non-functional' and 'Other'\n",
    "\n",
    "new_df = new_df.drop(['Non_functional','Other'],axis = 1)\n",
    "\n",
    "target_col = ['Corrective','Adaptive','Perfective','Implementation']\n",
    "multi_count = categories_count(new_df, target_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.to_csv('/data/new_data_merge.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apache-avro_126e9769f45f978f42321c4fc465198982df482b.json\n"
     ]
    }
   ],
   "source": [
    "csha = new_df['Commit ID'].values\n",
    "files = [c + '.json' for c in csha]\n",
    "application_name = new_df['project name'].values\n",
    "files_path = []\n",
    "for project_name, c in zip(application_name,files):\n",
    "    files_path.append(project_name + '_' + c)\n",
    "print(files_path[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-21T03:27:46.300541Z",
     "start_time": "2019-07-21T03:27:43.631478Z"
    }
   },
   "outputs": [],
   "source": [
    "def parse_json(filepath, files):\n",
    "    \"\"\"\n",
    "    function used to parse json of each commit json file\n",
    "\n",
    "    Args:\n",
    "        filepath_list - list of filepaths\n",
    "\n",
    "    Returns:\n",
    "        files_json - list object contains parsed information\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    files_json = []\n",
    "    commit_ids = []\n",
    "    # each commits\n",
    "    #files = os.listdir(filepath)\n",
    "    for path in files:\n",
    "        commit_id = path.split(\"_\")[1].split(\".\")[0]\n",
    "        if os.stat(filepath + path).st_size != 0 and path != 'desktop.ini':\n",
    "            with open(filepath + path, encoding=\"utf8\") as f:\n",
    "                data = json.load(f)\n",
    "                files_list = []\n",
    "                # each file in commits\n",
    "                for file in data['files']:\n",
    "                    # parse only cluster file\n",
    "                    for key in file.keys():\n",
    "                        if re.match('^.*_cluster$', key):\n",
    "                            actions_list = []\n",
    "                            actions = file[key]['actions']\n",
    "                            # each action in file\n",
    "                            for action in actions:\n",
    "                                actions_list.append(action['root'])\n",
    "                            files_list.append(actions_list)\n",
    "            if len(files_list) != 0:\n",
    "                files_json.append(files_list)\n",
    "                commit_ids.append(commit_id)\n",
    "    assert(len(commit_ids) == len(files_json))      \n",
    "    # return\n",
    "    return files_json, commit_ids\n",
    "\n",
    "files = files_path\n",
    "folder_path = './All_research/'\n",
    "all_files, csha = parse_json(folder_path, files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-21T03:27:46.324762Z",
     "start_time": "2019-07-21T03:27:46.305599Z"
    }
   },
   "outputs": [],
   "source": [
    "def preprocess_roots(files_data):\n",
    "    counting = {}\n",
    "    for file_index, files in enumerate(files_data):\n",
    "        for root_index, roots in enumerate(files):\n",
    "            for action_index, actions in enumerate(roots):\n",
    "                temp = actions.split(' at ')[0].strip()\n",
    "                tempq = []\n",
    "                if temp.startswith('INS'):\n",
    "                    tempq.append('INS')\n",
    "                    words = [temp.split('INS ')[1].split('to ')[0].strip()] + [\n",
    "                        temp.split('INS ')[1].rsplit('to ')[-1].strip()\n",
    "                    ]\n",
    "                    for items in words:\n",
    "                        items = items.split(':')[0].strip()\n",
    "                        tempq.append(items)\n",
    "                    if tempq[1] == 'TextElement' and tempq[-1] not in ['TagElement', 'TextElement']:\n",
    "                        tempq[-1] = ''\n",
    "                    temp = '_'.join(tempq)\n",
    "\n",
    "                if temp.startswith('UPDATE'):\n",
    "                    temp = 'UPDATE'\n",
    "                if temp.startswith('MOVE'):\n",
    "                    temp2 = temp.split('from ')[1].strip()\n",
    "                    tempq.append('MOVE')\n",
    "                    tempq.append(temp2.split(':')[0].strip())\n",
    "                    temp = '_'.join(tempq)\n",
    "\n",
    "                if temp.startswith('DEL'):\n",
    "                    tempq.append('DEL')\n",
    "                    tempq.append(temp.split('DEL ')[1].split(':')[0].strip())\n",
    "                    temp = '_'.join(tempq)\n",
    "                temp = temp.replace(' ', '_')\n",
    "                counting[temp] = counting.get(temp, 0) + 1\n",
    "                files_data[file_index][root_index][action_index] = temp\n",
    "    dic = {}\n",
    "    i = 0\n",
    "    for k, v in counting.items():\n",
    "        dic[k] = i\n",
    "        i += 1\n",
    "    return dic, files_data, counting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-21T03:27:46.475539Z",
     "start_time": "2019-07-21T03:27:46.328083Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "442\n"
     ]
    }
   ],
   "source": [
    "dic, datas, freq_dict = preprocess_roots(all_files)\n",
    "rev_dic = dict(zip(dic.values(), dic.keys()))\n",
    "print(len(dic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-21T03:27:46.488683Z",
     "start_time": "2019-07-21T03:27:46.478368Z"
    }
   },
   "outputs": [],
   "source": [
    "def actions2sentence(datas):\n",
    "    data_total = []\n",
    "    for files in datas:\n",
    "        data4file = []\n",
    "        for roots in files:\n",
    "            sentence = ' '.join(roots)\n",
    "            data4file.append(sentence)\n",
    "        data_total.append(data4file)\n",
    "    return data_total\n",
    "\n",
    "\n",
    "training_data = actions2sentence(datas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preperation: \n",
    "Prepare data for embedding and training ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.handle_labels import drop_labels\n",
    "from utils.handle_labels import group_labels\n",
    "from ast import literal_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "def permutate_files(csha, training_data): \n",
    "    commits_dic = dict()\n",
    "    for sha, training_file in zip(csha, training_data): \n",
    "        commits_dic[sha] = []\n",
    "        if len(training_file) <= 1: \n",
    "            tmp_permutate = list(itertools.permutations(training_file))\n",
    "            for permutated_file in tmp_permutate: \n",
    "                commits_dic[sha].append(list(permutated_file))\n",
    "        else: \n",
    "            commits_dic[sha].append(training_file)\n",
    "    return commits_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_list(commits_labels_df):\n",
    "    s= commits_labels_df.apply(lambda x: pd.Series(x['Files']),axis=1).stack().reset_index(level=1, drop=True)\n",
    "    s.name = \"Files\"\n",
    "    commits_labels_df = commits_labels_df.drop(\"Files\", axis=1) \n",
    "    commits_labels_df = commits_labels_df.join(s)\n",
    "    return commits_labels_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1922, 28)\n",
      "<class 'list'>\n",
      "['Testing', 'Bug fix']\n",
      "                                          0  \\\n",
      "0  3dd2210e79a8eb84378c370b32652f9a53f87a93   \n",
      "1  e691b66aadbed87ac4891cec2ca5136bc85cfe4d   \n",
      "2  1f959d076ed7f29c3f8a5c6e99cbfcc62c1058d9   \n",
      "3  1a7286afce71c005bae8d45e6b280e977f823a79   \n",
      "4  4c0a65457cb7a16578592cfb2278a2bb99f78cad   \n",
      "\n",
      "                                                   1  \n",
      "0  [[INS_ImportDeclaration_CompilationUnit INS_Fi...  \n",
      "1  [[INS_VariableDeclarationStatement_Block INS_T...  \n",
      "2  [[INS_ImportDeclaration_CompilationUnit INS_Im...  \n",
      "3  [[INS_ImportDeclaration_CompilationUnit INS_Im...  \n",
      "4  [[MOVE_SingleVariableDeclaration DEL_TypeParam...  \n",
      "exp_train_df shape: (624, 13)\n",
      "train_df shape: (624, 13)\n",
      "test_df shape: (153, 13)\n"
     ]
    }
   ],
   "source": [
    "# merge csha and training data to a dataframe\n",
    "commits_df = pd.DataFrame(data = [csha, training_data]).T\n",
    "commits_df.columns = [\"Commit ID\", \"Files\"]\n",
    "df_new = pd.read_csv('./data/new_data_merge.csv')\n",
    "print(df_new.shape)\n",
    "\n",
    "# import new dataset(contains 2000 commits) with labels\n",
    "# convert string to list\n",
    "df_new['categories'] = df_new['categories'].apply(lambda x: literal_eval(x))\n",
    "print(type(df_new['categories'].values[0]))\n",
    "print(df_new['categories'].values[0])\n",
    "df_new = df_new.drop(['Unnamed: 0'], axis = 1)\n",
    "\n",
    "# merge two dataframe and drop some of labels\n",
    "commits_labels_df = pd.merge(commits_df, df_new, on='Commit ID')\n",
    "commits_labels_df.head(1)\n",
    "commits_labels_df = drop_labels(commits_labels_df, [\"Testing\", \"Build\", \"Versioning\", \"Indentation\", \"Internationalization\", \"Merge\", \\\n",
    "                                                   \"Module Move\", \"Module Remove\", \"Source Control\", \"Rename\", \"Initialization\", \\\n",
    "                                                   \"Module Add\", \"Data\"])\n",
    "commits_labels_df = group_labels(commits_labels_df, [\"Cross\", \"Debug\"], \"Cross_\")\n",
    "commits_labels_df = group_labels(commits_labels_df, [\"Legal\", \"Documentation\"], \"Documentation_\")\n",
    "commits_labels_df.shape\n",
    "\n",
    "# split dataframe to train and test\n",
    "msk = np.random.rand(len(commits_labels_df)) < 0.8\n",
    "train_df = commits_labels_df[msk]\n",
    "test_df = commits_labels_df[~msk]\n",
    "\n",
    "# permutate train_df\n",
    "permutate_train_dic = permutate_files(train_df['Commit ID'],train_df['Files'])\n",
    "permutate_train_df = pd.DataFrame(list(permutate_train_dic.items()))\n",
    "print(permutate_train_df.head())\n",
    "permutate_train_df.columns = ['Commit ID','Files']\n",
    "train_df = train_df.drop([\"Files\"], axis=1)\n",
    "train_df['Files'] = permutate_train_df['Files'].values\n",
    "\n",
    "# expanded train_df list\n",
    "expanded_train_df = expand_list(train_df)\n",
    "\n",
    "print('exp_train_df shape:',expanded_train_df.shape)\n",
    "print('train_df shape:',train_df.shape)\n",
    "print('test_df shape:',test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-21T03:27:46.502749Z",
     "start_time": "2019-07-21T03:27:46.491433Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INS_ImportDeclaration_CompilationUnit INS_FieldDeclaration_TypeDeclaration INS_FieldDeclaration_TypeDeclaration UPDATE MOVE_VariableDeclarationFragment INS_ExpressionStatement_Block INS_ExpressionStatement_Block UPDATE UPDATE INS_SimpleName_MethodInvocation INS_SimpleName_MethodInvocation INS_SimpleName_MethodInvocation INS_ClassInstanceCreation_MethodInvocation DEL_SimpleName DEL_ExpressionStatement DEL_SimpleName INS_ImportDeclaration_CompilationUnit INS_VariableDeclarationStatement_Block INS_IfStatement_Block INS_ImportDeclaration_CompilationUnit INS_FieldDeclaration_TypeDeclaration INS_SingleVariableDeclaration_MethodDeclaration INS_SingleVariableDeclaration_MethodDeclaration INS_ExpressionStatement_Block INS_ExpressionStatement_Block INS_ExpressionStatement_Block INS_ExpressionStatement_Block INS_ExpressionStatement_Block INS_ExpressionStatement_Block UPDATE INS_ExpressionStatement_Block INS_IfStatement_Block INS_ExpressionStatement_Block INS_ExpressionStatement_Block UPDATE INS_MethodInvocation_MethodInvocation INS_MethodInvocation_MethodInvocation INS_ImportDeclaration_CompilationUnit INS_VariableDeclarationStatement_Block INS_IfStatement_Block INS_ImportDeclaration_CompilationUnit INS_ImportDeclaration_CompilationUnit INS_MethodDeclaration_TypeDeclaration INS_MethodDeclaration_TypeDeclaration INS_IfStatement_Block INS_MethodInvocation_MethodInvocation INS_ImportDeclaration_CompilationUnit INS_MethodDeclaration_TypeDeclaration INS_MethodDeclaration_TypeDeclaration INS_MethodDeclaration_TypeDeclaration INS_FieldDeclaration_TypeDeclaration INS_MethodDeclaration_TypeDeclaration INS_MethodDeclaration_TypeDeclaration MOVE_MethodDeclaration MOVE_MethodDeclaration INS_SingleVariableDeclaration_MethodDeclaration INS_Block_MethodDeclaration MOVE_MethodDeclaration INS_SingleVariableDeclaration_MethodDeclaration INS_SingleVariableDeclaration_MethodDeclaration MOVE_Block INS_ExpressionStatement_Block INS_MethodInvocation_ReturnStatement UPDATE MOVE_SimpleType UPDATE MOVE_SimpleType INS_SimpleName_SuperConstructorInvocation INS_SimpleName_SuperConstructorInvocation UPDATE MOVE_MethodInvocation MOVE_MethodInvocation INS_SimpleName_ClassInstanceCreation INS_SimpleName_ClassInstanceCreation DEL_ClassInstanceCreation DEL_MethodDeclaration DEL_MethodDeclaration\n",
      "  \n",
      "INS_Block_MethodDeclaration MOVE_Block DEL_FieldDeclaration DEL_ConstructorInvocation DEL_MethodDeclaration DEL_Block UPDATE UPDATE UPDATE\n"
     ]
    }
   ],
   "source": [
    "def concat_files_to_sentence(expanded_train_list): \n",
    "    concat_data = \"\"\n",
    "    tmp_list = []\n",
    "    for items in expanded_train_list:\n",
    "        concat_data = \" \".join(items)\n",
    "        tmp_list.append(concat_data)\n",
    "    return tmp_list\n",
    "concat_train_data = concat_files_to_sentence(expanded_train_df[\"Files\"])\n",
    "concat_test_data = concat_files_to_sentence(test_df[\"Files\"])\n",
    "print(concat_train_data[0])\n",
    "print(\"  \")\n",
    "print(concat_test_data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Determine File Threshold "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-21T03:27:53.112668Z",
     "start_time": "2019-07-21T03:27:46.510367Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<sample training data>:  ['INS_ImportDeclaration_CompilationUnit INS_FieldDeclaration_TypeDeclaration INS_FieldDeclaration_TypeDeclaration UPDATE MOVE_VariableDeclarationFragment INS_ExpressionStatement_Block INS_ExpressionStatement_Block UPDATE UPDATE INS_SimpleName_MethodInvocation INS_SimpleName_MethodInvocation INS_SimpleName_MethodInvocation INS_ClassInstanceCreation_MethodInvocation DEL_SimpleName DEL_ExpressionStatement DEL_SimpleName', 'INS_ImportDeclaration_CompilationUnit INS_VariableDeclarationStatement_Block INS_IfStatement_Block', 'INS_ImportDeclaration_CompilationUnit INS_FieldDeclaration_TypeDeclaration INS_SingleVariableDeclaration_MethodDeclaration INS_SingleVariableDeclaration_MethodDeclaration INS_ExpressionStatement_Block INS_ExpressionStatement_Block INS_ExpressionStatement_Block INS_ExpressionStatement_Block INS_ExpressionStatement_Block INS_ExpressionStatement_Block UPDATE INS_ExpressionStatement_Block INS_IfStatement_Block INS_ExpressionStatement_Block INS_ExpressionStatement_Block UPDATE INS_MethodInvocation_MethodInvocation INS_MethodInvocation_MethodInvocation', 'INS_ImportDeclaration_CompilationUnit INS_VariableDeclarationStatement_Block INS_IfStatement_Block', 'INS_ImportDeclaration_CompilationUnit INS_ImportDeclaration_CompilationUnit INS_MethodDeclaration_TypeDeclaration INS_MethodDeclaration_TypeDeclaration INS_IfStatement_Block INS_MethodInvocation_MethodInvocation', 'INS_ImportDeclaration_CompilationUnit INS_MethodDeclaration_TypeDeclaration INS_MethodDeclaration_TypeDeclaration INS_MethodDeclaration_TypeDeclaration INS_FieldDeclaration_TypeDeclaration INS_MethodDeclaration_TypeDeclaration INS_MethodDeclaration_TypeDeclaration MOVE_MethodDeclaration MOVE_MethodDeclaration INS_SingleVariableDeclaration_MethodDeclaration INS_Block_MethodDeclaration MOVE_MethodDeclaration INS_SingleVariableDeclaration_MethodDeclaration INS_SingleVariableDeclaration_MethodDeclaration MOVE_Block INS_ExpressionStatement_Block INS_MethodInvocation_ReturnStatement UPDATE MOVE_SimpleType UPDATE MOVE_SimpleType INS_SimpleName_SuperConstructorInvocation INS_SimpleName_SuperConstructorInvocation UPDATE MOVE_MethodInvocation MOVE_MethodInvocation INS_SimpleName_ClassInstanceCreation INS_SimpleName_ClassInstanceCreation DEL_ClassInstanceCreation DEL_MethodDeclaration DEL_MethodDeclaration']\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def get_seqlength(training_data):\n",
    "    max_root_len = 0\n",
    "    seqlength_list = []\n",
    "    for item in training_data:\n",
    "        seqlength_list.append(len(item.split()))\n",
    "        if len(item.split()) >  max_root_len: \n",
    "            max_root_len = len(item.split())\n",
    "    return max_root_len, seqlength_list\n",
    "\n",
    "def plot_hist(seqlength_list): \n",
    "    plt.figure(figsize=(20,10))\n",
    "    number_of_files = np.array(seqlength_list)\n",
    "    bincount = np.bincount(seqlength_list)\n",
    "    x = np.arange(1, len(bincount)+1)\n",
    "    n, bins, patches = plt.hist(seqlength_list,x)\n",
    "    plt.xlim((0, 500))\n",
    "    plt.ylim((0, 200))\n",
    "\n",
    "max_seqlength, sequence_list = get_seqlength(concat_train_data)\n",
    "print(\"<sample training data>: \", training_data[0])\n",
    "plot_hist(sequence_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-21T03:27:53.136546Z",
     "start_time": "2019-07-21T03:27:53.117407Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "241\n"
     ]
    }
   ],
   "source": [
    "# getting file threshold\n",
    "threshold = 0.95\n",
    "number_of_actions = [len(item.split()) for item in concat_train_data]\n",
    "\n",
    "def get_file_threshold(number_of_files, threshold = 0.95):\n",
    "    '''\n",
    "    get padding threshold for files dimension\n",
    "    \n",
    "    Args:\n",
    "        number_of_files - array of the number of files in each commits\n",
    "        threshold - drop all commits with its the number of files beyond this threshold\n",
    "    Returns:\n",
    "        padding threshold - number\n",
    "    '''\n",
    "    \n",
    "    total_files = len(number_of_files)\n",
    "    number_of_files = np.array(number_of_files)\n",
    "    bincount = np.bincount(number_of_files)\n",
    "\n",
    "    sum_file = 0\n",
    "    for index, item in enumerate(bincount):\n",
    "        sum_file += item\n",
    "        #print(index,item)\n",
    "        #print(sum_file)\n",
    "        if sum_file > threshold*total_files:\n",
    "            padding_files_threshold = index\n",
    "            break\n",
    "            \n",
    "    return padding_files_threshold\n",
    "\n",
    "length_threshold = get_file_threshold(number_of_actions, threshold)\n",
    "print(length_threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "expanded_train_df = expanded_train_df.drop([\"Files\"], axis=1)\n",
    "test_df = test_df.drop([\"Files\"], axis=1)\n",
    "expanded_train_df[\"Files\"] = concat_train_data \n",
    "test_df[\"Files\"] = concat_test_data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-21T03:27:53.530703Z",
     "start_time": "2019-07-21T03:27:53.490766Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Commit ID', 'project name', 'commit_message', 'Maintenance',\n",
      "       'Feature Add', 'Bug fix', 'Clean up', 'Refactoring', 'Token Replace',\n",
      "       'categories', 'Cross_', 'Documentation_', 'Files', 'len_seq'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "expanded_train_df['len_seq'] = expanded_train_df.apply(lambda row: len(row['Files'].split()), axis = 1)\n",
    "test_df['len_seq'] = test_df.apply(lambda row: len(row['Files'].split()), axis = 1)\n",
    "expanded_train_df = expanded_train_df[expanded_train_df['len_seq'] <= length_threshold].reset_index(drop = True)\n",
    "test_df = test_df[test_df['len_seq'] <= length_threshold].reset_index(drop = True)\n",
    "print(test_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-21T03:27:53.960319Z",
     "start_time": "2019-07-21T03:27:47.213Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "traing labels shape:  (593,)\n",
      "test labels shape:  (143,)\n"
     ]
    }
   ],
   "source": [
    "target_col = [\"Maintenance\", \"Feature Add\", \"Bug fix\", \"Clean up\", \"Refactoring\", \"Token Replace\", \"Cross_\", \"Documentation_\"]\n",
    "y_train = expanded_train_df[\"Maintenance\"].values\n",
    "y_test = test_df[\"Maintenance\"].values\n",
    "print(\"traing labels shape: \", y_train.shape) \n",
    "print(\"test labels shape: \", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenize and Pad data \n",
    "We tokenize the data and pad with the token <PAD/>.<br/> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-21T03:27:53.966249Z",
     "start_time": "2019-07-21T03:27:47.781Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 11, 11, 1, 35, 6, 6, 1, 1, 10, 10, 10, 85, 7, 15, 7, 2, 12, 17, 2, 11, 18, 18, 6, 6, 6, 6, 6, 6, 1, 6, 17, 6, 6, 1, 27, 27, 2, 12, 17, 2, 2, 3, 3, 17, 27, 2, 3, 3, 3, 11, 3, 3, 16, 16, 18, 37, 16, 18, 18, 8, 6, 76, 1, 19, 1, 19, 194, 194, 1, 5, 5, 48, 48, 58, 13, 13]\n",
      "[38, 6, 28, 164, 15, 21, 1, 1, 1]\n",
      "(593, 242)\n",
      "(143, 242)\n"
     ]
    }
   ],
   "source": [
    "#Training \n",
    "train_docs = expanded_train_df['Files'].values\n",
    "t_train = Tokenizer(filters = '', lower=False)\n",
    "t_train.fit_on_texts(train_docs)\n",
    "\n",
    "#Testing \n",
    "test_docs = test_df['Files'].values \n",
    "t_test = Tokenizer(filters = '', lower=False)\n",
    "t_test.fit_on_texts(test_docs)\n",
    "\n",
    "sequences_train = t_train.texts_to_sequences(train_docs)\n",
    "sequences_test = t_test.texts_to_sequences(test_docs)\n",
    "print(sequences_train[0])\n",
    "print(sequences_test[0])\n",
    "\n",
    "#Pad training data \n",
    "padded_seq_train = pad_sequences(sequences_train, maxlen=length_threshold + 1, padding=\"post\", truncating=\"post\")\n",
    "print(padded_seq_train.shape)\n",
    "\n",
    "#Pad testing data \n",
    "padded_seq_test = pad_sequences(sequences_test, maxlen=length_threshold + 1, padding=\"post\", truncating=\"post\")\n",
    "print(padded_seq_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Testing and Training Set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-21T03:27:53.968217Z",
     "start_time": "2019-07-21T03:27:48.097Z"
    }
   },
   "outputs": [],
   "source": [
    "vocabulary_train = t_train.word_index\n",
    "vocabulary_test = t_test.word_index \n",
    "\n",
    "\n",
    "vocabulary_inv_train = dict((v, k) for k, v in vocabulary_train.items())\n",
    "vocabulary_inv_test = dict((v, k) for k, v in vocabulary_test.items())\n",
    "vocabulary_inv_train[0] = \"<PAD/>\"\n",
    "vocabulary_inv_test[0] = \"<PAD/>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-21T03:27:53.969406Z",
     "start_time": "2019-07-21T03:27:48.398Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "(593, 242)\n",
      "(143, 242)\n",
      "(593,)\n",
      "(143,)\n"
     ]
    }
   ],
   "source": [
    "X_train = padded_seq_train \n",
    "X_test = padded_seq_test\n",
    "print(X_train[10, :])\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_embedding(filename):\n",
    "    \"\"\"\n",
    "    load embedding as python dictionary {root<str>: embeddings<np_array>}\n",
    "    :param filename: embedding.txt \n",
    "    :return: dictionary object mapping root to embeddings \n",
    "    \"\"\"\n",
    "    if not os.path.exists(filename): \n",
    "        print(\"please run 'Store Pre-Trained Embeddings Cell!'\")\n",
    "    else: \n",
    "        with open(filename, \"r\") as f: \n",
    "            lines = f.readlines()\n",
    "            f.close()\n",
    "            # create map of words to vectors \n",
    "            embedding = dict()\n",
    "            for line in lines: \n",
    "                comp = line.split()\n",
    "                # map of <str, numpy array> \n",
    "                embedding[comp[0]] = np.asarray(comp[1:], dtype='float32')\n",
    "            return embedding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_embed = load_embedding(\"embedding.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-21T03:27:53.979720Z",
     "start_time": "2019-07-21T03:27:50.237Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train static shape: (593, 242, 300)\n",
      "x_test static shape: (143, 242, 300)\n"
     ]
    }
   ],
   "source": [
    "X_train = np.stack([np.stack([pre_embed[vocabulary_inv_train[action]] for action in commit]) for commit in X_train])\n",
    "X_test = np.stack([np.stack([pre_embed[vocabulary_inv_test[action]] for action in commit]) for commit in X_test])\n",
    "print(\"x_train static shape:\", X_train.shape)\n",
    "print(\"x_test static shape:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN for text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-21T03:27:53.982096Z",
     "start_time": "2019-07-21T03:27:50.555Z"
    }
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Flatten, Input, MaxPooling1D, Convolution1D, Embedding\n",
    "from keras.layers.merge import Concatenate\n",
    "from keras import regularizers\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-21T03:27:53.992898Z",
     "start_time": "2019-07-21T03:27:51.761Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import hamming_loss\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score \n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "def print_evaluation_scores(y_test, predicted):\n",
    "    \n",
    "    print('Accuracy:', accuracy_score(y_test, predicted))\n",
    "    print('F1-score macro:', f1_score(y_test, predicted, average='macro'))\n",
    "    print('F1-score micro:', f1_score(y_test, predicted, average='micro'))\n",
    "    print('F1-score weighted:', f1_score(y_test, predicted, average='weighted'))\n",
    "    print('Hamming_loss:', hamming_loss(y_test, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-21T03:27:53.987127Z",
     "start_time": "2019-07-21T03:27:50.921Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 593 samples, validate on 143 samples\n",
      "Epoch 1/20\n",
      " - 6s - loss: 0.7021 - acc: 0.4671 - val_loss: 0.6720 - val_acc: 0.5594\n",
      "Epoch 2/20\n",
      " - 2s - loss: 0.6582 - acc: 0.5683 - val_loss: 0.6705 - val_acc: 0.5245\n",
      "Epoch 3/20\n",
      " - 2s - loss: 0.6435 - acc: 0.5987 - val_loss: 0.6725 - val_acc: 0.5594\n",
      "Epoch 4/20\n",
      " - 3s - loss: 0.6223 - acc: 0.6341 - val_loss: 0.6729 - val_acc: 0.5734\n",
      "Epoch 5/20\n",
      " - 2s - loss: 0.6070 - acc: 0.6762 - val_loss: 0.6750 - val_acc: 0.5734\n",
      "Epoch 6/20\n",
      " - 2s - loss: 0.5923 - acc: 0.7066 - val_loss: 0.6777 - val_acc: 0.5524\n",
      "Epoch 7/20\n",
      " - 2s - loss: 0.5714 - acc: 0.7285 - val_loss: 0.6796 - val_acc: 0.5455\n",
      "Epoch 8/20\n",
      " - 2s - loss: 0.5564 - acc: 0.7184 - val_loss: 0.6817 - val_acc: 0.5524\n",
      "Epoch 9/20\n",
      " - 2s - loss: 0.5516 - acc: 0.7015 - val_loss: 0.6844 - val_acc: 0.5385\n",
      "Epoch 10/20\n",
      " - 2s - loss: 0.5306 - acc: 0.7622 - val_loss: 0.6890 - val_acc: 0.5594\n",
      "Epoch 11/20\n",
      " - 3s - loss: 0.5148 - acc: 0.7555 - val_loss: 0.6933 - val_acc: 0.5455\n",
      "Epoch 12/20\n",
      " - 3s - loss: 0.5046 - acc: 0.7555 - val_loss: 0.6983 - val_acc: 0.5455\n",
      "Epoch 13/20\n",
      " - 2s - loss: 0.4879 - acc: 0.7875 - val_loss: 0.7036 - val_acc: 0.5385\n",
      "Epoch 14/20\n",
      " - 2s - loss: 0.4764 - acc: 0.7926 - val_loss: 0.7103 - val_acc: 0.5455\n",
      "Epoch 15/20\n",
      " - 2s - loss: 0.4804 - acc: 0.7690 - val_loss: 0.7136 - val_acc: 0.5524\n",
      "Epoch 16/20\n",
      " - 2s - loss: 0.4694 - acc: 0.7757 - val_loss: 0.7154 - val_acc: 0.5385\n",
      "Epoch 17/20\n",
      " - 2s - loss: 0.4604 - acc: 0.7723 - val_loss: 0.7164 - val_acc: 0.5455\n",
      "Epoch 18/20\n",
      " - 2s - loss: 0.4430 - acc: 0.7875 - val_loss: 0.7181 - val_acc: 0.5455\n",
      "Epoch 19/20\n",
      " - 2s - loss: 0.4207 - acc: 0.8179 - val_loss: 0.7228 - val_acc: 0.5664\n",
      "Epoch 20/20\n",
      " - 2s - loss: 0.4222 - acc: 0.8094 - val_loss: 0.7290 - val_acc: 0.5804\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x132d4f8d0>"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# hyparameters\n",
    "model_type = \"CNN-non-static\"  # CNN-rand|CNN-non-static|CNN-static\n",
    "\n",
    "# Model Hyperparameters\n",
    "embedding_dim = 300\n",
    "filter_sizes = (3,4,5)\n",
    "num_filters = 5\n",
    "dropout_prob = (0.5, 0.5)\n",
    "hidden_dims = 64\n",
    "\n",
    "# Training parameters\n",
    "batch_size = 64\n",
    "num_epochs = 20 #50\n",
    "\n",
    "sequence_length = length_threshold\n",
    "\n",
    "# input\n",
    "input_shape = (sequence_length + 1, embedding_dim)\n",
    "model_input = Input(shape=input_shape)\n",
    "\n",
    "z = model_input\n",
    "\n",
    "# dropout layer\n",
    "# z = Dropout(dropout_prob[0])(z)\n",
    "\n",
    "# Convolutional block\n",
    "conv_blocks = []\n",
    "for sz in filter_sizes: # Feature > Maintenance > Clean  up > Bug fix > \n",
    "    conv = Convolution1D(filters=num_filters,\n",
    "                         kernel_size=sz,\n",
    "                         padding=\"valid\",\n",
    "                         activation=\"relu\",\n",
    "                         strides=1)(z)\n",
    "    conv = MaxPooling1D(pool_size=2)(conv)\n",
    "    conv = Flatten()(conv)\n",
    "    conv_blocks.append(conv)\n",
    "\n",
    "z = Concatenate()(conv_blocks) if len(conv_blocks) > 1 else conv_blocks[0]\n",
    "\n",
    "z = Dropout(dropout_prob[1])(z)\n",
    "\n",
    "#z = Dense(hidden_dims, activation=\"relu\")(z)\n",
    "\n",
    "model_output = Dense(1, activation=\"sigmoid\")(z)\n",
    "\n",
    "model = Model(model_input, model_output)\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer= optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, \n",
    "                                                                     epsilon=None, decay=0.0, amsgrad=False), \n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "model.fit(X_train, y_train, batch_size=batch_size, epochs=num_epochs,\n",
    "          validation_data=(X_test, y_test), verbose=2, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-21T03:27:53.994119Z",
     "start_time": "2019-07-21T03:27:52.337Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5804195804195804\n",
      "F1-score macro: 0.5799059929494712\n",
      "F1-score micro: 0.5804195804195804\n",
      "F1-score weighted: 0.5812413203717551\n",
      "Hamming_loss: 0.4195804195804196\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "\n",
    "y_pred_bool = (y_pred > 0.5)\n",
    "\n",
    "predictions = y_pred_bool.astype(int)\n",
    "print_evaluation_scores(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_14 (InputLayer)           (None, 242, 300)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_14 (Conv1D)              (None, 240, 5)       4505        input_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_15 (Conv1D)              (None, 239, 5)       6005        input_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_16 (Conv1D)              (None, 238, 5)       7505        input_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_14 (MaxPooling1D) (None, 120, 5)       0           conv1d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_15 (MaxPooling1D) (None, 119, 5)       0           conv1d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_16 (MaxPooling1D) (None, 119, 5)       0           conv1d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_14 (Flatten)            (None, 600)          0           max_pooling1d_14[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_15 (Flatten)            (None, 595)          0           max_pooling1d_15[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_16 (Flatten)            (None, 595)          0           max_pooling1d_16[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 1790)         0           flatten_14[0][0]                 \n",
      "                                                                 flatten_15[0][0]                 \n",
      "                                                                 flatten_16[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_27 (Dropout)            (None, 1790)         0           concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_27 (Dense)                (None, 1)            1791        dropout_27[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 19,806\n",
      "Trainable params: 19,806\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN for Text - Pytorch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import torch.autograd as autograd\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_Text(nn.Module):\n",
    "    \n",
    "    def __init__(self, args):\n",
    "        super(CNN_Text, self).__init__()\n",
    "        self.args = args\n",
    "        \n",
    "        V = args.embed_num        # number of embedding\n",
    "        D = args.embed_dim        # embedding dimension\n",
    "        C = args.class_num        # number of class\n",
    "        \n",
    "        Ci = 1                    # input channel - number of channels of input data             \n",
    "        Co = args.kernel_num      # output channels - number of filters\n",
    "        Ks = args.kernel_sizes    # cnn kernel sizes - List - size dimension (conv_size, embedding_dimension)\n",
    "\n",
    "        #self.embed = nn.Embedding(V, D)                                       # embedding layer\n",
    "        # self.convs1 = [nn.Conv2d(Ci, Co, (K, D)) for K in Ks]\n",
    "        self.convs1 = nn.ModuleList([nn.Conv2d(Ci, Co, (K, D)) for K in Ks])  # List of convolution layer\n",
    "        '''\n",
    "        self.conv13 = nn.Conv2d(Ci, Co, (3, D))\n",
    "        self.conv14 = nn.Conv2d(Ci, Co, (4, D))\n",
    "        self.conv15 = nn.Conv2d(Ci, Co, (5, D))\n",
    "        '''\n",
    "        self.dropout = nn.Dropout(args.dropout)                               # dropout layer\n",
    "        self.fc1 = nn.Linear(len(Ks)*Co, C)                                   # Dense Layer (input dimension, C classes)\n",
    "\n",
    "    def conv_and_pool(self, x, conv):\n",
    "        x = F.relu(conv(x)).squeeze(3)  # (N, Co, W)\n",
    "        x = F.max_pool1d(x, x.size(2)).squeeze(2)\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        #x = self.embed(x)  # (N, W, D)\n",
    "        \n",
    "#         if self.args.static:\n",
    "#             x = Variable(x)\n",
    "\n",
    "        x = x.unsqueeze(1)  # (N, Ci, W, D)\n",
    "\n",
    "        x = [F.relu(conv(x)).squeeze(3) for conv in self.convs1]  # [(N, Co, W), ...]*len(Ks)\n",
    "\n",
    "        x = [F.max_pool1d(i, i.size(2)).squeeze(2) for i in x]  # [(N, Co), ...]*len(Ks)\n",
    "\n",
    "        x = torch.cat(x, 1)\n",
    "\n",
    "        '''\n",
    "        x1 = self.conv_and_pool(x,self.conv13) #(N,Co)\n",
    "        x2 = self.conv_and_pool(x,self.conv14) #(N,Co)\n",
    "        x3 = self.conv_and_pool(x,self.conv15) #(N,Co)\n",
    "        x = torch.cat((x1, x2, x3), 1) # (N,len(Ks)*Co)\n",
    "        '''\n",
    "        x = self.dropout(x)  # (N, len(Ks)*Co)\n",
    "        logit = self.fc1(x)  # (N, C)\n",
    "        return logit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CodeChangeDataset(Dataset):\n",
    "    \"\"\"Face Landmarks dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, X, y, transform = None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            data: dataframe contains features and labels\n",
    "            target_col : target columns name\n",
    "        \"\"\"\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.X.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sentence = self.X[idx]\n",
    "        label = np.asarray(self.y[idx])\n",
    "        sample = {'feature': sentence, 'label': label}\n",
    "\n",
    "        return sample\n",
    "\n",
    "class ToTensor(object):\n",
    "    \"\"\"Convert ndarrays in sample to Tensors.\"\"\"\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        sentence, lable = sample['sentence'], sample['label']\n",
    "        \n",
    "        return {'feature': torch.from_numpy(sentence),\n",
    "                'label': torch.from_numpy(label)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(dataloader, model, args):\n",
    "    model.eval()\n",
    "    corrects, avg_loss = 0, 0\n",
    "    for idx, batch in enumerate(dataloader,0):\n",
    "        feature, target = batch['feature'], batch['label']\n",
    "        if args.cuda:\n",
    "            feature, target = feature.cuda(), target.cuda()\n",
    "\n",
    "        logit = model(feature)\n",
    "        logit = logit.squeeze(1)\n",
    "        loss = F.cross_entropy(logit, target, size_average=False)\n",
    "\n",
    "        avg_loss += loss.item()\n",
    "        corrects += (torch.max(logit, 1)[1].view(target.size()).data == target.data).sum()\n",
    "\n",
    "    size = len(dataloader.dataset)\n",
    "    avg_loss /= size\n",
    "    accuracy = 100.0 * corrects/size\n",
    "    print('Evaluation - loss: {:.6f}  acc: {:.4f}%({}/{}) \\n'.format(avg_loss, accuracy, corrects, size))\n",
    "    return accuracy\n",
    "\n",
    "def train(dataloader, val_dataloader,  model, args):\n",
    "    if args.cuda:\n",
    "        model.cuda()\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=args.lr)\n",
    "    \n",
    "    steps = 0\n",
    "    best_acc = 0\n",
    "    last_step = 0\n",
    "    model.train()\n",
    "    \n",
    "    for epoch in range(1, args.epochs+1):\n",
    "        running_loss = 0.0\n",
    "        for i, batch_data in enumerate(dataloader, 0):\n",
    "             # get the feature and target tensor\n",
    "            feature, target = batch['feature'], batch['label']\n",
    "            if args.cuda:\n",
    "                feature, target = feature.cuda(), target.cuda()\n",
    "            \n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # output : model(input)\n",
    "            output = model(feature)\n",
    "\n",
    "            loss = F.cross_entropy(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            steps += 1\n",
    "            running_loss += loss.item()\n",
    "            \n",
    "        # print training loss - each epoch\n",
    "        # corrects = (torch.max(output, 1)[1].view(target.size()).data == target.data).sum()\n",
    "        # accuracy = 100.0 * corrects/dataloader.batch_size\n",
    "        print('Epoch[{}] - loss: {:.6f}'.format(epoch, running_loss/i))\n",
    "\n",
    "        # evaluation on validation set\n",
    "        dev_acc = eval(val_dataloader, model, args)\n",
    "        if dev_acc > best_acc:\n",
    "            best_acc = dev_acc\n",
    "            last_step = steps\n",
    "#                     if args.save_best:\n",
    "#                         save(model, args.save_dir, 'best', steps)\n",
    "        else:\n",
    "            if steps - last_step >= args.early_stop:\n",
    "                print('early stop by {} steps.'.format(args.early_stop))\n",
    "#             elif steps % args.save_interval == 0:\n",
    "#                 save(model, args.save_dir, 'snapshot', steps)\n",
    "\n",
    "\n",
    "def predict(text, model, text_field, label_feild, cuda_flag):\n",
    "    assert isinstance(text, str)\n",
    "    model.eval()\n",
    "    # text = text_field.tokenize(text)\n",
    "    text = text_field.preprocess(text)\n",
    "    text = [[text_field.vocab.stoi[x] for x in text]]\n",
    "    x = torch.tensor(text)\n",
    "    x = autograd.Variable(x)\n",
    "    if cuda_flag:\n",
    "        x = x.cuda()\n",
    "    print(x)\n",
    "    output = model(x)\n",
    "    _, predicted = torch.max(output, 1)\n",
    "    #return label_feild.vocab.itos[predicted.data[0][0]+1]\n",
    "    return label_feild.vocab.itos[predicted.data[0]+1]\n",
    "\n",
    "\n",
    "# def save(model, save_dir, save_prefix, steps):\n",
    "#     if not os.path.isdir(save_dir):\n",
    "#         os.makedirs(save_dir)\n",
    "#     save_prefix = os.path.join(save_dir, save_prefix)\n",
    "#     save_path = '{}_steps_{}.pt'.format(save_prefix, steps)\n",
    "#     torch.save(model.state_dict(), save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args:\n",
    "    def __init__(self, parameters):\n",
    "        # model parameters\n",
    "        self.lr = parameters['lr'] if parameters.get('lr') != None else 0.001\n",
    "        self.epochs = parameters['epoch'] if parameters.get('epoch') != None else 10\n",
    "        self.batch_size = parameters['batch_size'] if parameters.get('batch_size') != None else 64\n",
    "        self.shuffle = parameters['shuffle'] if parameters.get('shuffle') != None else False                     # whether to shuffle data after every epoch\n",
    "        self.dropout = parameters['dropout'] if parameters.get('dropout') != None else 0.5\n",
    "        self.max_norm = parameters['l2-norm'] if parameters.get('l2-norm') != None else 3.0                      # l2 norm\n",
    "        self.embed_dim = parameters['embed_dim'] if parameters.get('embed_dim') != None else 300                 # embedding dimension\n",
    "        self.embed_num = parameters['embed_num'] if parameters.get('embed_num') != None else 5000               # number of filters for each conv\n",
    "        self.kernel_num = parameters['kernel_num'] if parameters.get('kernel_num') != None else 10               # number of filters for each conv\n",
    "        self.kernel_sizes = parameters['kernel_sizes'] if parameters.get('kernel_sizes') != None else [3,4,5]    # list of kernel sizes\n",
    "        self.class_num = parameters['class_num'] if parameters.get('class_num') != None else 2\n",
    "        \n",
    "        # training precocess parameters\n",
    "        self.log_interval = parameters['log_interval'] if  parameters.get('log_interval') != None else 1\n",
    "        self.test_interval = parameters['test_interval'] if  parameters.get('test_interval') != None else 10\n",
    "        self.save_interval = parameters['save_interval'] if  parameters.get('save_interval') != None else 100\n",
    "        self.save_dir = parameters['save_dir'] if  parameters.get('save_dir') != None else './'\n",
    "        self.early_stop = parameters['early_stop'] if  parameters.get('early_stop') != None else 1000\n",
    "        self.save_best = parameters['save_best'] if  parameters.get('save_best') != None else True\n",
    "        self.no_cuda = parameters['no_cuda'] if  parameters.get('no_cuda') != None else True            # wether to use gpu\n",
    "        self.device = parameters['device'] if  parameters.get('device') != None else -1                 # which device to use -1 means cpu\n",
    "        self.cuda = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[1] - loss: 0.713753\n",
      "Evaluation - loss: 0.668496  acc: 57.0000%(82/143) \n",
      "\n",
      "Epoch[2] - loss: 0.486003\n",
      "Evaluation - loss: 0.634749  acc: 62.0000%(89/143) \n",
      "\n",
      "Epoch[3] - loss: 0.369082\n",
      "Evaluation - loss: 0.623375  acc: 65.0000%(93/143) \n",
      "\n",
      "Epoch[4] - loss: 0.289246\n",
      "Evaluation - loss: 0.624355  acc: 65.0000%(93/143) \n",
      "\n",
      "Epoch[5] - loss: 0.235246\n",
      "Evaluation - loss: 0.633821  acc: 64.0000%(92/143) \n",
      "\n",
      "Epoch[6] - loss: 0.197215\n",
      "Evaluation - loss: 0.647443  acc: 63.0000%(91/143) \n",
      "\n",
      "Epoch[7] - loss: 0.168674\n",
      "Evaluation - loss: 0.663970  acc: 62.0000%(90/143) \n",
      "\n",
      "Epoch[8] - loss: 0.147588\n",
      "Evaluation - loss: 0.682554  acc: 62.0000%(89/143) \n",
      "\n",
      "Epoch[9] - loss: 0.132097\n",
      "Evaluation - loss: 0.702651  acc: 60.0000%(87/143) \n",
      "\n",
      "Epoch[10] - loss: 0.120645\n",
      "Evaluation - loss: 0.724343  acc: 60.0000%(87/143) \n",
      "\n",
      "Epoch[11] - loss: 0.112046\n",
      "Evaluation - loss: 0.745797  acc: 60.0000%(87/143) \n",
      "\n",
      "Epoch[12] - loss: 0.105420\n",
      "Evaluation - loss: 0.766113  acc: 60.0000%(87/143) \n",
      "\n",
      "Epoch[13] - loss: 0.100205\n",
      "Evaluation - loss: 0.785496  acc: 61.0000%(88/143) \n",
      "\n",
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "Exiting from training early\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/queues.py\", line 240, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/queues.py\", line 240, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/queues.py\", line 240, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/queues.py\", line 240, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n"
     ]
    }
   ],
   "source": [
    "parameters = {'class_num':2, 'epoch':20, 'batch_size':64 }\n",
    "args = Args(parameters)\n",
    "\n",
    "# change dir\n",
    "args.save_dir = os.path.join(args.save_dir, datetime.datetime.now().strftime('%Y-%m-%d_%H-%M-%S'))\n",
    "# check gpu avialiable\n",
    "args.cuda = (not args.no_cuda) and torch.cuda.is_available()\n",
    "\n",
    "# data loader\n",
    "train_data = CodeChangeDataset(X_train, y_train, transform = ToTensor())\n",
    "test_data = CodeChangeDataset(X_test, y_test, transform = ToTensor())\n",
    "\n",
    "train_dataloader = DataLoader(train_data, batch_size=args.batch_size,shuffle=True, num_workers=4)\n",
    "test_dataloader = DataLoader(test_data, batch_size=args.batch_size, shuffle = False, num_workers=4)\n",
    "\n",
    "# model\n",
    "cnn = CNN_Text(args)\n",
    "# if args.snapshot is not None:\n",
    "#     print('\\nLoading model from {}...'.format(args.snapshot))\n",
    "#     cnn.load_state_dict(torch.load(args.snapshot))\n",
    "\n",
    "# if args.cuda:\n",
    "#     torch.cuda.set_device(args.device)\n",
    "#     cnn = cnn.cuda()\n",
    "\n",
    "try:\n",
    "    train(train_dataloader, test_dataloader, cnn, args)\n",
    "except KeyboardInterrupt:\n",
    "    print('\\n' + '-' * 89)\n",
    "    print('Exiting from training early')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

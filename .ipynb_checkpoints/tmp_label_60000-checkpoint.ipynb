{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import os \n",
    "import numpy\n",
    "import json "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training_commit_samples.csv, bug_doc_clean.json "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Commit ID', 'total_files', 'deleted_files', 'testing', 'maintenance',\n",
       "       'build', 'csha', 'commit message'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"training_commits_samples.csv\")\n",
    "df.columns "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerprocess commit message "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'008cd8a209564a958e9065a5f6ff05526a41f4a5'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csha_list = df['csha'].values\n",
    "csha_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/kelechi/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
      "[nltk_data] Downloading package words to /home/kelechi/nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/kelechi/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('words')\n",
    "nltk.download('wordnet')\n",
    "from nltk.corpus import stopwords\n",
    "from ast import literal_eval\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "GIT_SVN_RE = re.compile('git-svn-id:.*\\n')\n",
    "issue_number_re = re.compile('[A-Za-z]+[-]\\d+')\n",
    "created_by_moe = re.compile('Created by MOE:.*\\n')\n",
    "MOE_ID = re.compile('MOE_MIGRATED_REVID=.*\\n')\n",
    "developer_name_re = re.compile('\\(.*\\)\\n')\n",
    "HTTP_RE = re.compile('(http|https):.*\\n')\n",
    "EMAIL_RE = re.compile('[a-zA-Z0-9]+@[a-zA-Z0-9]+\\.[a-zA-Z0-9-.]+')\n",
    "Other_RE = re.compile('(Author|Authors|Reviewers|Reviewer).*\\n')\n",
    "Bracket_RE = re.compile('\\[.*\\]')\n",
    "\n",
    "break_line_re = re.compile('\\n')\n",
    "digital = re.compile('[0-9]')\n",
    "BAD_SYMBOLS_RE = re.compile('[^0-9a-z ]')\n",
    "STOPWORDS = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_prepare(text):\n",
    "    \"\"\"\n",
    "        text: a string\n",
    "        \n",
    "        return: modified initial string\n",
    "    \"\"\"\n",
    "    text = GIT_SVN_RE.sub('', text)\n",
    "    text = issue_number_re.sub('', text)\n",
    "    text = created_by_moe.sub('', text)\n",
    "    text = MOE_ID.sub('', text)\n",
    "    text = developer_name_re.sub('\\n', text)\n",
    "    text = HTTP_RE.sub('\\n', text)\n",
    "    text = EMAIL_RE.sub('\\n', text)\n",
    "    text = Other_RE.sub('', text)\n",
    "    text = Bracket_RE.sub('', text)\n",
    "\n",
    "    text = text.lower()  # lowercase text\n",
    "    text = break_line_re.sub(' ', text)  # remove all \\n\n",
    "    text = digital.sub('', text)\n",
    "    text = BAD_SYMBOLS_RE.sub(\n",
    "        '', text)  # delete symbols which are in BAD_SYMBOLS_RE from text\n",
    "\n",
    "    text = ' '.join([x for x in text.split() if x and x not in STOPWORDS\n",
    "                     ])  # delete stopwords from text\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVRO-321.  Restore java RPC interop tests.\n",
      "\n",
      "git-svn-id: https://svn.apache.org/repos/asf/hadoop/avro/trunk@906635 13f79535-47bb-0310-9956-ffa450edef68\n",
      "\n",
      "restore java rpc interop tests\n"
     ]
    }
   ],
   "source": [
    "test_commit = df['commit message'].values[232]\n",
    "print(test_commit)\n",
    "test_commit = text_prepare(test_commit)\n",
    "print(test_commit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 merge pull request thiruapachethiru added tests fixed couple bugs also formatted code\n",
      "1 datafilewriterappendto leads intermittent ioexception write\n",
      "2 java add command line tool generate schema files protocol contributed bertrand dechoux\n",
      "3 timeconversions implement getrecommendedschema closes signedoffby gabor szadovszky signedoffby sacharya signedoffby nandor kollar\n",
      "4 java fix genericdatarecordequals correctly compare schemas fix schemaequals consider order\n",
      "5 java fix decimal conversion bytebuffer\n",
      "6 java add support snappy codec newer mapreduce api contributed matt mead\n",
      "7 improve invalid file format error message\n",
      "8 java fix builder api correctly handle default values enums\n",
      "9 java permit maven find imports within project contributed alexandre normand\n"
     ]
    }
   ],
   "source": [
    "df['commit message'] = [text_prepare(line) for line in df['commit message']]\n",
    "for index, line in enumerate(df['commit message'].values):\n",
    "    if index < 10:\n",
    "        print(index, line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spell Checking "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyenchant\n",
      "Installing collected packages: pyenchant\n",
      "Successfully installed pyenchant-2.0.0\n"
     ]
    }
   ],
   "source": [
    "!pip3 install pyenchant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-65-05e02a5ec4b9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m \u001b[0mremove_noise_message\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mremove_noise_words\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'commit message'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mremove_noise_message\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-65-05e02a5ec4b9>\u001b[0m in \u001b[0;36mremove_noise_words\u001b[0;34m(message_array)\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mtext\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmessage_array\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         text = ' '.join(\n\u001b[0;32m---> 16\u001b[0;31m             [x for x in text.split() if x and x not in wrong_words])\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-65-05e02a5ec4b9>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mtext\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmessage_array\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         text = ' '.join(\n\u001b[0;32m---> 16\u001b[0;31m             [x for x in text.split() if x and x not in wrong_words])\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from enchant.checker import SpellChecker\n",
    "chkr = SpellChecker(\"en_US\")\n",
    "wrong_words = []\n",
    "for index, text in enumerate(df['commit message']):\n",
    "    chkr.set_text(text)\n",
    "    for err in chkr:\n",
    "        if err.word not in wrong_words:\n",
    "            wrong_words.append(err.word)\n",
    "        #   print(index, err.word)\n",
    "\n",
    "\n",
    "def remove_noise_words(message_array):\n",
    "    res = []\n",
    "    for text in message_array:\n",
    "        text = ' '.join(\n",
    "            [x for x in text.split() if x and x not in wrong_words])\n",
    "        res.append(text)\n",
    "    return res\n",
    "\n",
    "\n",
    "def replace_nosie_words_with_sth(message_array):\n",
    "    res = []\n",
    "    for text in message_array:\n",
    "        # replace wrong word with something\n",
    "        new_text = []\n",
    "        for x in text.split():\n",
    "            if x and x in wrong_words:\n",
    "                new_text.append('something')\n",
    "            else:\n",
    "                new_text.append(x)\n",
    "\n",
    "        text = ' '.join(new_text)\n",
    "        res.append(text)\n",
    "    return res\n",
    "\n",
    "\n",
    "remove_noise_message = remove_noise_words(df['commit message'].values)\n",
    "for index, line in enumerate(remove_noise_message):\n",
    "    if index < 10:\n",
    "        print(index, line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

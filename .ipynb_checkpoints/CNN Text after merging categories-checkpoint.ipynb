{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-21T03:27:43.628313Z",
     "start_time": "2019-07-21T03:27:34.819524Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras import optimizers\n",
    "\n",
    "\n",
    "import sys\n",
    "from collections import Counter \n",
    "import pprint \n",
    "import math\n",
    "import argparse \n",
    "import os\n",
    "import collections\n",
    "import json\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import random\n",
    "import time \n",
    "import pandas as pd\n",
    "import itertools\n",
    "import tensorflow as tf\n",
    "\n",
    "seed_value= 0\n",
    "os.environ['PYTHONHASHSEED']=str(seed_value)\n",
    "random.seed(seed_value)\n",
    "np.random.seed(seed_value)\n",
    "tf.set_random_seed(seed_value)\n",
    "from keras import backend as K\n",
    "session_conf = tf.ConfigProto(intra_op_parallelism_threads=4, inter_op_parallelism_threads=4)\n",
    "sess = tf.Session(graph=tf.get_default_graph(), config=session_conf)\n",
    "K.set_session(sess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "\n",
    "# funtions to handle labels\n",
    "from utils.handle_labels import get_tag_counts_and_labels\n",
    "from utils.handle_labels import drop_labels\n",
    "from utils.handle_labels import group_labels\n",
    "from utils.handle_labels import categories_count\n",
    "from utils.handle_labels import get_imbalance\n",
    "from utils.handle_labels import label_distribution\n",
    "from utils.handle_labels import number_of_labels\n",
    "#from utils.message_preprocess import message_processing\n",
    "# plot untils funcion\n",
    "from utils.plot_utils import pie_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1922, 28)\n",
      "<class 'list'>\n",
      "['Testing', 'Bug fix']\n",
      "Maintenance : 891\n",
      "Feature Add : 330\n",
      "Bug fix : 266\n",
      "Documentation : 237\n",
      "Clean up : 192\n",
      "Refactoring : 111\n",
      "Indentation : 48\n",
      "Token Replace : 40\n",
      "Source Control : 30\n",
      "Cross : 24\n",
      "Legal : 18\n",
      "Debug : 10\n",
      "Module Remove : 6\n",
      "Rename : 5\n",
      "Module Move : 5\n",
      "Versioning : 4\n",
      "Merge : 3\n",
      "Initialization : 2\n",
      "Module Add : 1\n",
      "Internationalization : 1\n",
      "Data : 1\n",
      "1    1625\n",
      "2     226\n",
      "3      35\n",
      "4       7\n",
      "5       3\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non_functional : 70\n",
      "Corrective : 266\n",
      "Other : 34\n",
      "Adaptive : 239\n",
      "Perfective : 1130\n",
      "Implementation : 334\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('data/commit_data_new.csv')\n",
    "print(df.shape)\n",
    "\n",
    "# convert string to list\n",
    "from ast import literal_eval\n",
    "\n",
    "df['categories'] = df['categories'].apply(lambda x: literal_eval(x))\n",
    "print(type(df['categories'].values[0]))\n",
    "print(df['categories'].values[0])\n",
    "df = df.drop(['Unnamed: 0'], axis = 1)\n",
    "df.head()\n",
    "\n",
    "#tags_counts,target_columns = get_tag_counts_and_labels(df)\n",
    "#print(target_columns)\n",
    "\n",
    "# drop testing and build\n",
    "new_df = drop_labels(df, ['Testing', 'Build'])\n",
    "_ , target_col = get_tag_counts_and_labels(new_df)\n",
    "multi_count = number_of_labels(new_df, target_col)\n",
    "\n",
    "def group_labels_new(df, labels_to_group, new_label):\n",
    "    '''\n",
    "    Group some of labels\n",
    "\n",
    "    Args:\n",
    "        df - dataframe\n",
    "        labels_to_group -  List of labels you want to group\n",
    "        new_label -  string - new label name of grouped labels\n",
    "\n",
    "    Returns:\n",
    "        new_df - dataframe after grouped\n",
    "    '''\n",
    "    new_df = df.copy()\n",
    "\n",
    "    # generate new labels by group labels\n",
    "    def create_new_label(row, labels):\n",
    "        new_label = 0  # initialize new label\n",
    "        for label in labels:\n",
    "            if row[label] == 1:\n",
    "                new_label = 1  # if one of labels in grouped labels is 1 the new label is 1\n",
    "        return new_label\n",
    "\n",
    "    new_df[new_label] = df.apply(lambda row: create_new_label(row, labels_to_group), axis=1)\n",
    "\n",
    "    # generate list of new_categories\n",
    "\n",
    "    return new_df\n",
    "\n",
    "new_df = group_labels_new(new_df, ['Bug fix'], 'Corrective')\n",
    "new_df = group_labels_new(new_df, ['Internationalization', 'Documentation','Data'], 'Adaptive')\n",
    "new_df = group_labels_new(new_df, ['Clean up', 'Indentation','Maintenance','Module Move','Module Remove','Refactoring'], 'Perfective')\n",
    "new_df = group_labels_new(new_df, ['Initialization', 'Feature Add','Module Add','Internationalization'], 'Implementation')\n",
    "new_df = group_labels_new(new_df, ['Legal', 'Module Remove','Rename','Token Replace','Merge'], 'Non_functional')\n",
    "new_df = group_labels_new(new_df, ['Cross','Debug'], 'Other')\n",
    "\n",
    "target_col = ['Corrective','Adaptive','Perfective','Implementation','Non_functional','Other']\n",
    "multi_count = categories_count(new_df, target_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adaptive : 239\n",
      "Corrective : 266\n",
      "Perfective : 1130\n",
      "Implementation : 334\n"
     ]
    }
   ],
   "source": [
    "# Drop 'Non-functional' and 'Other'\n",
    "\n",
    "new_df = new_df.drop(['Non_functional','Other'],axis = 1)\n",
    "\n",
    "target_col = ['Corrective','Adaptive','Perfective','Implementation']\n",
    "multi_count = categories_count(new_df, target_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apache-avro_126e9769f45f978f42321c4fc465198982df482b.json\n"
     ]
    }
   ],
   "source": [
    "csha = new_df['Commit ID'].values\n",
    "files = [c + '.json' for c in csha]\n",
    "application_name = new_df['project name'].values\n",
    "files_path = []\n",
    "for project_name, c in zip(application_name,files):\n",
    "    files_path.append(project_name + '_' + c)\n",
    "print(files_path[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-21T03:27:46.300541Z",
     "start_time": "2019-07-21T03:27:43.631478Z"
    }
   },
   "outputs": [],
   "source": [
    "def parse_json(filepath, files):\n",
    "    \"\"\"\n",
    "    function used to parse json of each commit json file\n",
    "\n",
    "    Args:\n",
    "        filepath_list - list of filepaths\n",
    "\n",
    "    Returns:\n",
    "        files_json - list object contains parsed information\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    files_json = []\n",
    "    commit_ids = []\n",
    "    # each commits\n",
    "    #files = os.listdir(filepath)\n",
    "    for path in files:\n",
    "        commit_id = path.split(\"_\")[1].split(\".\")[0]\n",
    "        try:\n",
    "            if os.stat(filepath + path).st_size != 0 and path != 'desktop.ini':\n",
    "                with open(filepath + path, encoding=\"utf8\") as f:\n",
    "                    data = json.load(f)\n",
    "                    files_list = []\n",
    "                    # each file in commits\n",
    "                    for file in data['files']:\n",
    "                        # parse only cluster file\n",
    "                        for key in file.keys():\n",
    "                            if re.match('^.*_cluster$', key):\n",
    "                                actions_list = []\n",
    "                                actions = file[key]['actions']\n",
    "                                # each action in file\n",
    "                                for action in actions:\n",
    "                                    actions_list.append(action['root'])\n",
    "                                files_list.append(actions_list)\n",
    "                if len(files_list) != 0:\n",
    "                    files_json.append(files_list)\n",
    "                    commit_ids.append(commit_id)\n",
    "        except FileNotFoundError as e: \n",
    "            continue \n",
    "    assert(len(commit_ids) == len(files_json))      \n",
    "    # return\n",
    "    return files_json, commit_ids\n",
    "\n",
    "files = files_path\n",
    "folder_path = 'C:\\\\Users\\\\ichel\\\\Desktop\\\\shared_ReFiles\\\\AllFiles_Research\\\\'\n",
    "all_files, csha = parse_json(folder_path, files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-21T03:27:46.324762Z",
     "start_time": "2019-07-21T03:27:46.305599Z"
    }
   },
   "outputs": [],
   "source": [
    "def preprocess_roots(files_data):\n",
    "    counting = {}\n",
    "    for file_index, files in enumerate(files_data):\n",
    "        for root_index, roots in enumerate(files):\n",
    "            for action_index, actions in enumerate(roots):\n",
    "                temp = actions.split(' at ')[0].strip()\n",
    "                tempq = []\n",
    "                if temp.startswith('INS'):\n",
    "                    tempq.append('INS')\n",
    "                    words = [temp.split('INS ')[1].split('to ')[0].strip()] + [\n",
    "                        temp.split('INS ')[1].rsplit('to ')[-1].strip()\n",
    "                    ]\n",
    "                    for items in words:\n",
    "                        items = items.split(':')[0].strip()\n",
    "                        tempq.append(items)\n",
    "                    if tempq[1] == 'TextElement' and tempq[-1] not in ['TagElement', 'TextElement']:\n",
    "                        tempq[-1] = ''\n",
    "                    temp = '_'.join(tempq)\n",
    "\n",
    "                if temp.startswith('UPDATE'):\n",
    "                    temp = 'UPDATE'\n",
    "                if temp.startswith('MOVE'):\n",
    "                    temp2 = temp.split('from ')[1].strip()\n",
    "                    tempq.append('MOVE')\n",
    "                    tempq.append(temp2.split(':')[0].strip())\n",
    "                    temp = '_'.join(tempq)\n",
    "\n",
    "                if temp.startswith('DEL'):\n",
    "                    tempq.append('DEL')\n",
    "                    tempq.append(temp.split('DEL ')[1].split(':')[0].strip())\n",
    "                    temp = '_'.join(tempq)\n",
    "                temp = temp.replace(' ', '_')\n",
    "                counting[temp] = counting.get(temp, 0) + 1\n",
    "                files_data[file_index][root_index][action_index] = temp\n",
    "    dic = {}\n",
    "    i = 0\n",
    "    for k, v in counting.items():\n",
    "        dic[k] = i\n",
    "        i += 1\n",
    "    return dic, files_data, counting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-21T03:27:46.475539Z",
     "start_time": "2019-07-21T03:27:46.328083Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "520\n"
     ]
    }
   ],
   "source": [
    "dic, datas, freq_dict = preprocess_roots(all_files)\n",
    "rev_dic = dict(zip(dic.values(), dic.keys()))\n",
    "print(len(dic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-21T03:27:46.488683Z",
     "start_time": "2019-07-21T03:27:46.478368Z"
    }
   },
   "outputs": [],
   "source": [
    "def actions2sentence(datas):\n",
    "    data_total = []\n",
    "    for files in datas:\n",
    "        data4file = []\n",
    "        for roots in files:\n",
    "            sentence = ' '.join(roots)\n",
    "            data4file.append(sentence)\n",
    "        data_total.append(data4file)\n",
    "    return data_total\n",
    "\n",
    "\n",
    "training_data = actions2sentence(datas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preperation: \n",
    "Prepare data for embedding and training ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.handle_labels import drop_labels\n",
    "from utils.handle_labels import group_labels\n",
    "from ast import literal_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def permutate_files(csha, training_data): \n",
    "    commits_dic = dict()\n",
    "    for sha, training_file in zip(csha, training_data): \n",
    "        commits_dic[sha] = []\n",
    "        if len(training_file) <= 5: \n",
    "            tmp_permutate = list(itertools.permutations(training_file))\n",
    "            for permutated_file in tmp_permutate: \n",
    "                commits_dic[sha].append(list(permutated_file))\n",
    "        else: \n",
    "            commits_dic[sha].append(training_file)\n",
    "    return commits_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_list(commits_labels_df):\n",
    "    s= commits_labels_df.apply(lambda x: pd.Series(x['Files']),axis=1).stack().reset_index(level=1, drop=True)\n",
    "    s.name = \"Files\"\n",
    "    commits_labels_df = commits_labels_df.drop(\"Files\", axis=1) \n",
    "    commits_labels_df = commits_labels_df.join(s)\n",
    "    return commits_labels_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1896, 29)\n",
      "                                          0  \\\n",
      "0  1bdd23092beec998a8275516297e246c82e54b1d   \n",
      "1  9db37bd90005695c703f9d092651891a5e39a80a   \n",
      "2  099ff5c3e92b56912791324a2f40251fbee3fdce   \n",
      "3  3bec45e1961d9c126dbe7b36d4290b3de273721c   \n",
      "4  db00d3afd4738021a05f81a7820129d62950efd7   \n",
      "\n",
      "                                                   1  \n",
      "0  [[, , , , , , , , , , , , , , , , , , , , , , ...  \n",
      "1  [[INS_TryStatement_Block MOVE_TryStatement MOV...  \n",
      "2  [[INS_MethodDeclaration_TypeDeclaration, , DEL...  \n",
      "3  [[INS_IfStatement_Block INS_SimpleName_MethodI...  \n",
      "4  [[DEL_MethodDeclaration DEL_MethodDeclaration,...  \n",
      "exp_train_df shape: (9248, 30)\n",
      "train_df shape: (1312, 30)\n",
      "test_df shape: (344, 30)\n"
     ]
    }
   ],
   "source": [
    "# merge csha and training data to a dataframe\n",
    "commits_df = pd.DataFrame(data = [csha, training_data]).T\n",
    "commits_df.columns = [\"Commit ID\", \"Files\"]\n",
    "print(new_df.shape)\n",
    "\n",
    "# merge two dataframe and drop some of labels\n",
    "commits_labels_df = pd.merge(commits_df, new_df, on='Commit ID')\n",
    "\n",
    "# split dataframe to train and test\n",
    "msk = np.random.rand(len(commits_labels_df)) < 0.8\n",
    "train_df = commits_labels_df[msk]\n",
    "test_df = commits_labels_df[~msk]\n",
    "\n",
    "# permutate train_df\n",
    "permutate_train_dic = permutate_files(train_df['Commit ID'],train_df['Files'])\n",
    "permutate_train_df = pd.DataFrame(list(permutate_train_dic.items()))\n",
    "print(permutate_train_df.head())\n",
    "permutate_train_df.columns = ['Commit ID','Files']\n",
    "train_df = train_df.drop([\"Files\"], axis=1)\n",
    "train_df['Files'] = permutate_train_df['Files'].values\n",
    "\n",
    "# expanded train_df list\n",
    "expanded_train_df = expand_list(train_df)\n",
    "\n",
    "print('exp_train_df shape:',expanded_train_df.shape)\n",
    "print('train_df shape:',train_df.shape)\n",
    "print('test_df shape:',test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-21T03:27:46.502749Z",
     "start_time": "2019-07-21T03:27:46.491433Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                     UPDATE          UPDATE   UPDATE  UPDATE           UPDATE                                \n",
      "  \n",
      "UPDATE UPDATE\n"
     ]
    }
   ],
   "source": [
    "def concat_files_to_sentence(expanded_train_list): \n",
    "    concat_data = \"\"\n",
    "    tmp_list = []\n",
    "    for items in expanded_train_list:\n",
    "        concat_data = \" \".join(items)\n",
    "        tmp_list.append(concat_data)\n",
    "    return tmp_list\n",
    "concat_train_data = concat_files_to_sentence(expanded_train_df[\"Files\"])\n",
    "concat_test_data = concat_files_to_sentence(test_df[\"Files\"])\n",
    "print(concat_train_data[0])\n",
    "print(\"  \")\n",
    "print(concat_test_data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Determine File Threshold "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-21T03:27:53.112668Z",
     "start_time": "2019-07-21T03:27:46.510367Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<sample training data>:  ['UPDATE UPDATE']\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def get_seqlength(training_data):\n",
    "    max_root_len = 0\n",
    "    seqlength_list = []\n",
    "    for item in training_data:\n",
    "        seqlength_list.append(len(item.split()))\n",
    "        if len(item.split()) >  max_root_len: \n",
    "            max_root_len = len(item.split())\n",
    "    return max_root_len, seqlength_list\n",
    "\n",
    "def plot_hist(seqlength_list): \n",
    "    plt.figure(figsize=(20,10))\n",
    "    number_of_files = np.array(seqlength_list)\n",
    "    bincount = np.bincount(seqlength_list)\n",
    "    x = np.arange(1, len(bincount)+1)\n",
    "    n, bins, patches = plt.hist(seqlength_list,x)\n",
    "    plt.xlim((0, 500))\n",
    "    plt.ylim((0, 200))\n",
    "\n",
    "max_seqlength, sequence_list = get_seqlength(concat_train_data)\n",
    "print(\"<sample training data>: \", training_data[0])\n",
    "plot_hist(sequence_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-21T03:27:53.136546Z",
     "start_time": "2019-07-21T03:27:53.117407Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "223\n"
     ]
    }
   ],
   "source": [
    "# getting file threshold\n",
    "threshold = 0.95\n",
    "number_of_actions = [len(item.split()) for item in concat_train_data]\n",
    "\n",
    "def get_file_threshold(number_of_files, threshold = 0.95):\n",
    "    '''\n",
    "    get padding threshold for files dimension\n",
    "    \n",
    "    Args:\n",
    "        number_of_files - array of the number of files in each commits\n",
    "        threshold - drop all commits with its the number of files beyond this threshold\n",
    "    Returns:\n",
    "        padding threshold - number\n",
    "    '''\n",
    "    \n",
    "    total_files = len(number_of_files)\n",
    "    number_of_files = np.array(number_of_files)\n",
    "    bincount = np.bincount(number_of_files)\n",
    "\n",
    "    sum_file = 0\n",
    "    for index, item in enumerate(bincount):\n",
    "        sum_file += item\n",
    "        #print(index,item)\n",
    "        #print(sum_file)\n",
    "        if sum_file > threshold*total_files:\n",
    "            padding_files_threshold = index\n",
    "            break\n",
    "            \n",
    "    return padding_files_threshold\n",
    "\n",
    "length_threshold = get_file_threshold(number_of_actions, threshold)\n",
    "print(length_threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "expanded_train_df = expanded_train_df.drop([\"Files\"], axis=1)\n",
    "test_df = test_df.drop([\"Files\"], axis=1)\n",
    "expanded_train_df[\"Files\"] = concat_train_data \n",
    "test_df[\"Files\"] = concat_test_data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-21T03:27:53.530703Z",
     "start_time": "2019-07-21T03:27:53.490766Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Commit ID', 'project name', 'commit_message', 'Maintenance',\n",
      "       'Feature Add', 'Bug fix', 'Documentation', 'Clean up', 'Refactoring',\n",
      "       'Indentation', 'Token Replace', 'Source Control', 'Cross', 'Legal',\n",
      "       'Debug', 'Module Remove', 'Module Move', 'Rename', 'Versioning',\n",
      "       'Merge', 'Initialization', 'Internationalization', 'Data', 'Module Add',\n",
      "       'categories', 'Corrective', 'Adaptive', 'Perfective', 'Implementation',\n",
      "       'Files', 'len_seq'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "expanded_train_df['len_seq'] = expanded_train_df.apply(lambda row: len(row['Files'].split()), axis = 1)\n",
    "test_df['len_seq'] = test_df.apply(lambda row: len(row['Files'].split()), axis = 1)\n",
    "expanded_train_df = expanded_train_df[expanded_train_df['len_seq'] <= length_threshold].reset_index(drop = True)\n",
    "test_df = test_df[test_df['len_seq'] <= length_threshold].reset_index(drop = True)\n",
    "print(test_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-21T03:27:53.960319Z",
     "start_time": "2019-07-21T03:27:47.213Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "traing labels shape:  (8854, 4)\n",
      "test labels shape:  (331, 4)\n"
     ]
    }
   ],
   "source": [
    "target_col =  ['Corrective','Adaptive','Perfective','Implementation']\n",
    "y_train = expanded_train_df[target_col].values\n",
    "y_test = test_df[target_col].values\n",
    "print(\"traing labels shape: \", y_train.shape) \n",
    "print(\"test labels shape: \", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenize and Pad data \n",
    "We tokenize the data and pad with the token <PAD/>.<br/> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-21T03:27:53.966249Z",
     "start_time": "2019-07-21T03:27:47.781Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 1, 1]\n",
      "[1, 1]\n",
      "(8854, 224)\n",
      "(331, 224)\n"
     ]
    }
   ],
   "source": [
    "#Training \n",
    "train_docs = expanded_train_df['Files'].values\n",
    "t_train = Tokenizer(filters = '', lower=False)\n",
    "t_train.fit_on_texts(train_docs)\n",
    "\n",
    "#Testing \n",
    "test_docs = test_df['Files'].values \n",
    "t_test = Tokenizer(filters = '', lower=False)\n",
    "t_test.fit_on_texts(test_docs)\n",
    "\n",
    "sequences_train = t_train.texts_to_sequences(train_docs)\n",
    "sequences_test = t_test.texts_to_sequences(test_docs)\n",
    "print(sequences_train[0])\n",
    "print(sequences_test[0])\n",
    "\n",
    "#Pad training data \n",
    "padded_seq_train = pad_sequences(sequences_train, maxlen=length_threshold + 1, padding=\"post\", truncating=\"post\")\n",
    "print(padded_seq_train.shape)\n",
    "\n",
    "#Pad testing data \n",
    "padded_seq_test = pad_sequences(sequences_test, maxlen=length_threshold + 1, padding=\"post\", truncating=\"post\")\n",
    "print(padded_seq_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Testing and Training Set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-21T03:27:53.968217Z",
     "start_time": "2019-07-21T03:27:48.097Z"
    }
   },
   "outputs": [],
   "source": [
    "vocabulary_train = t_train.word_index\n",
    "vocabulary_test = t_test.word_index \n",
    "\n",
    "\n",
    "vocabulary_inv_train = dict((v, k) for k, v in vocabulary_train.items())\n",
    "vocabulary_inv_test = dict((v, k) for k, v in vocabulary_test.items())\n",
    "vocabulary_inv_train[0] = \"<PAD/>\"\n",
    "vocabulary_inv_test[0] = \"<PAD/>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-21T03:27:53.969406Z",
     "start_time": "2019-07-21T03:27:48.398Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 17  17  17  17   5   5   5   5   5   5  40  16  47  12   1 362  16  16\n",
      "  47  12  18  48  18   1  18  18  48   1  18  48  18  18   1   1  18   1\n",
      "   7  20  67   8  57  57 260 260   1   1  18  48  18   1  18  48  18   1\n",
      "  18  48  18  18  48  18   9 131  23  26  53 288   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0]\n",
      "(8854, 224)\n",
      "(331, 224)\n",
      "(8854, 4)\n",
      "(331, 4)\n"
     ]
    }
   ],
   "source": [
    "X_train = padded_seq_train \n",
    "X_test = padded_seq_test\n",
    "print(X_train[10, :])\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_embedding(filename):\n",
    "    \"\"\"\n",
    "    load embedding as python dictionary {root<str>: embeddings<np_array>}\n",
    "    :param filename: embedding.txt \n",
    "    :return: dictionary object mapping root to embeddings \n",
    "    \"\"\"\n",
    "    if not os.path.exists(filename): \n",
    "        print(\"please run 'Store Pre-Trained Embeddings Cell!'\")\n",
    "    else: \n",
    "        with open(filename, \"r\") as f: \n",
    "            lines = f.readlines()\n",
    "            f.close()\n",
    "            # create map of words to vectors \n",
    "            embedding = dict()\n",
    "            for line in lines: \n",
    "                comp = line.split()\n",
    "                # map of <str, numpy array> \n",
    "                embedding[comp[0]] = np.asarray(comp[1:], dtype='float32')\n",
    "            return embedding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_embed = load_embedding(\"embedding.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-21T03:27:53.979720Z",
     "start_time": "2019-07-21T03:27:50.237Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train static shape: (8854, 224, 300)\n",
      "x_test static shape: (331, 224, 300)\n"
     ]
    }
   ],
   "source": [
    "X_train = np.stack([np.stack([pre_embed[vocabulary_inv_train[action]] for action in commit]) for commit in X_train])\n",
    "X_test = np.stack([np.stack([pre_embed[vocabulary_inv_test[action]] for action in commit]) for commit in X_test])\n",
    "print(\"x_train static shape:\", X_train.shape)\n",
    "print(\"x_test static shape:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN for text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-21T03:27:53.982096Z",
     "start_time": "2019-07-21T03:27:50.555Z"
    }
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Flatten, Input, MaxPooling1D, Convolution1D, Embedding\n",
    "from keras.layers.merge import Concatenate\n",
    "from keras import regularizers\n",
    "import warnings\n",
    "import keras\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-21T03:27:53.992898Z",
     "start_time": "2019-07-21T03:27:51.761Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import hamming_loss\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score \n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "def print_evaluation_scores(y_test, predicted):\n",
    "    \n",
    "    print('Accuracy:', accuracy_score(y_test, predicted))\n",
    "    print('F1-score macro:', f1_score(y_test, predicted, average='macro'))\n",
    "    print('F1-score micro:', f1_score(y_test, predicted, average='micro'))\n",
    "    print('F1-score weighted:', f1_score(y_test, predicted, average='weighted'))\n",
    "    print('Hamming_loss:', hamming_loss(y_test, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-21T03:27:53.987127Z",
     "start_time": "2019-07-21T03:27:50.921Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8854 samples, validate on 331 samples\n",
      "Epoch 1/50\n",
      " - 6s - loss: 0.6098 - top1_acc: 0.4665 - val_loss: 0.5511 - val_top1_acc: 0.5287\n",
      "Epoch 2/50\n",
      " - 5s - loss: 0.4812 - top1_acc: 0.5323 - val_loss: 0.5641 - val_top1_acc: 0.5559\n",
      "Epoch 3/50\n",
      " - 5s - loss: 0.3883 - top1_acc: 0.5939 - val_loss: 0.6119 - val_top1_acc: 0.5498\n",
      "Epoch 4/50\n",
      " - 5s - loss: 0.3003 - top1_acc: 0.6843 - val_loss: 0.6755 - val_top1_acc: 0.4955\n",
      "Epoch 5/50\n",
      " - 5s - loss: 0.2339 - top1_acc: 0.7276 - val_loss: 0.7015 - val_top1_acc: 0.5227\n",
      "Epoch 6/50\n",
      " - 5s - loss: 0.1820 - top1_acc: 0.7532 - val_loss: 0.6846 - val_top1_acc: 0.5166\n",
      "Epoch 7/50\n",
      " - 5s - loss: 0.1566 - top1_acc: 0.7843 - val_loss: 0.6891 - val_top1_acc: 0.5076\n",
      "Epoch 8/50\n",
      " - 5s - loss: 0.1425 - top1_acc: 0.7829 - val_loss: 0.6953 - val_top1_acc: 0.5076\n",
      "Epoch 9/50\n",
      " - 5s - loss: 0.1292 - top1_acc: 0.7947 - val_loss: 0.7230 - val_top1_acc: 0.4985\n",
      "Epoch 10/50\n",
      " - 5s - loss: 0.1215 - top1_acc: 0.8022 - val_loss: 0.7274 - val_top1_acc: 0.4985\n",
      "Epoch 11/50\n",
      " - 5s - loss: 0.1129 - top1_acc: 0.8047 - val_loss: 0.7437 - val_top1_acc: 0.5015\n",
      "Epoch 12/50\n",
      " - 5s - loss: 0.1074 - top1_acc: 0.8053 - val_loss: 0.7668 - val_top1_acc: 0.5015\n",
      "Epoch 13/50\n",
      " - 5s - loss: 0.1041 - top1_acc: 0.8164 - val_loss: 0.7734 - val_top1_acc: 0.5015\n",
      "Epoch 14/50\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-74-c0ddacadfeaf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m model.fit(X_train, y_train, batch_size=batch_size, epochs=num_epochs,\n\u001b[1;32m---> 57\u001b[1;33m           validation_data=(X_test, y_test), verbose=2, shuffle = False)\n\u001b[0m",
      "\u001b[1;32mc:\\users\\ichel\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1039\u001b[1;33m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1040\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32mc:\\users\\ichel\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m    193\u001b[0m                 \u001b[0mbatch_logs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'batch'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch_index\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    194\u001b[0m                 \u001b[0mbatch_logs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'size'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 195\u001b[1;33m                 \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    196\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mindices_for_conversion_to_dense\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ichel\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\callbacks.py\u001b[0m in \u001b[0;36mon_batch_begin\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m     91\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_delta_ts_batch_begin\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mt_before_callbacks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 93\u001b[1;33m         \u001b[0mdelta_t_median\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmedian\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_delta_ts_batch_begin\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     94\u001b[0m         if (self._delta_t_batch > 0. and\n\u001b[0;32m     95\u001b[0m            \u001b[0mdelta_t_median\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0.95\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_delta_t_batch\u001b[0m \u001b[1;32mand\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ichel\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\numpy\\lib\\function_base.py\u001b[0m in \u001b[0;36mmedian\u001b[1;34m(a, axis, out, overwrite_input, keepdims)\u001b[0m\n\u001b[0;32m   3495\u001b[0m     \"\"\"\n\u001b[0;32m   3496\u001b[0m     r, k = _ureduce(a, func=_median, axis=axis, out=out,\n\u001b[1;32m-> 3497\u001b[1;33m                     overwrite_input=overwrite_input)\n\u001b[0m\u001b[0;32m   3498\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3499\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ichel\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\numpy\\lib\\function_base.py\u001b[0m in \u001b[0;36m_ureduce\u001b[1;34m(a, func, **kwargs)\u001b[0m\n\u001b[0;32m   3403\u001b[0m         \u001b[0mkeepdim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3404\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3405\u001b[1;33m     \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3406\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3407\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ichel\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\numpy\\lib\\function_base.py\u001b[0m in \u001b[0;36m_median\u001b[1;34m(a, axis, out, overwrite_input)\u001b[0m\n\u001b[0;32m   3528\u001b[0m             \u001b[0mpart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3529\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3530\u001b[1;33m         \u001b[0mpart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpartition\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkth\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3531\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3532\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mpart\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ichel\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36mpartition\u001b[1;34m(a, kth, axis, kind, order)\u001b[0m\n\u001b[0;32m    732\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    733\u001b[0m         \u001b[0ma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0masanyarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"K\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 734\u001b[1;33m     \u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpartition\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkth\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkind\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    735\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    736\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# hyparameters\n",
    "model_type = \"CNN-non-static\"  # CNN-rand|CNN-non-static|CNN-static\n",
    "\n",
    "import functools\n",
    "top1_acc = functools.partial(keras.metrics.top_k_categorical_accuracy, k=1)\n",
    "\n",
    "top1_acc.__name__ = 'top1_acc'\n",
    "\n",
    "# Model Hyperparameters\n",
    "embedding_dim = 300\n",
    "filter_sizes = (5,5,10)\n",
    "num_filters = 10\n",
    "dropout_prob = (0.5, 0.5)\n",
    "hidden_dims = 64\n",
    "\n",
    "# Training parameters\n",
    "batch_size = 64\n",
    "num_epochs = 50 #50\n",
    "\n",
    "sequence_length = length_threshold\n",
    "\n",
    "# input\n",
    "input_shape = (sequence_length + 1, embedding_dim)\n",
    "model_input = Input(shape=input_shape)\n",
    "\n",
    "z = model_input\n",
    "\n",
    "# dropout layer\n",
    "# z = Dropout(dropout_prob[0])(z)\n",
    "\n",
    "# Convolutional block\n",
    "conv_blocks = []\n",
    "for sz in filter_sizes: # Feature > Maintenance > Clean  up > Bug fix > \n",
    "    conv = Convolution1D(filters=num_filters,\n",
    "                         kernel_size=sz,\n",
    "                         padding=\"same\",\n",
    "                         activation=\"relu\",\n",
    "                         strides=1)(z)\n",
    "    conv = MaxPooling1D(pool_size=2)(conv)\n",
    "    conv = Flatten()(conv)\n",
    "    conv_blocks.append(conv)\n",
    "\n",
    "z = Concatenate()(conv_blocks) if len(conv_blocks) > 1 else conv_blocks[0]\n",
    "\n",
    "z = Dropout(dropout_prob[1])(z)\n",
    "\n",
    "z = Dense(hidden_dims, activation=\"relu\")(z)\n",
    "\n",
    "model_output = Dense(4, activation=\"sigmoid\")(z)\n",
    "\n",
    "model = Model(model_input, model_output)\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer= optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, \n",
    "                                                                     epsilon=None, decay=0.0, amsgrad=False), \n",
    "              metrics=[top1_acc])\n",
    "\n",
    "model.fit(X_train, y_train, batch_size=batch_size, epochs=num_epochs,\n",
    "          validation_data=(X_test, y_test), verbose=2, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-21T03:27:53.994119Z",
     "start_time": "2019-07-21T03:27:52.337Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.3867069486404834\n",
      "F1-score macro: 0.20563014709370575\n",
      "F1-score micro: 0.5007587253414265\n",
      "F1-score weighted: 0.41091072764168035\n",
      "Hamming_loss: 0.24848942598187312\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "\n",
    "y_pred_bool = (y_pred > 0.5)\n",
    "\n",
    "predictions = y_pred_bool.astype(int)\n",
    "print_evaluation_scores(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_14 (InputLayer)           (None, 242, 300)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_14 (Conv1D)              (None, 240, 5)       4505        input_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_15 (Conv1D)              (None, 239, 5)       6005        input_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_16 (Conv1D)              (None, 238, 5)       7505        input_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_14 (MaxPooling1D) (None, 120, 5)       0           conv1d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_15 (MaxPooling1D) (None, 119, 5)       0           conv1d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_16 (MaxPooling1D) (None, 119, 5)       0           conv1d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_14 (Flatten)            (None, 600)          0           max_pooling1d_14[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_15 (Flatten)            (None, 595)          0           max_pooling1d_15[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_16 (Flatten)            (None, 595)          0           max_pooling1d_16[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 1790)         0           flatten_14[0][0]                 \n",
      "                                                                 flatten_15[0][0]                 \n",
      "                                                                 flatten_16[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_27 (Dropout)            (None, 1790)         0           concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_27 (Dense)                (None, 1)            1791        dropout_27[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 19,806\n",
      "Trainable params: 19,806\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN for Text - Pytorch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import torch.autograd as autograd\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_Text(nn.Module):\n",
    "    \n",
    "    def __init__(self, args):\n",
    "        super(CNN_Text, self).__init__()\n",
    "        self.args = args\n",
    "        \n",
    "        V = args.embed_num        # number of embedding\n",
    "        D = args.embed_dim        # embedding dimension\n",
    "        C = args.class_num        # number of class\n",
    "        \n",
    "        Ci = 1                    # input channel - number of channels of input data             \n",
    "        Co = args.kernel_num      # output channels - number of filters\n",
    "        Ks = args.kernel_sizes    # cnn kernel sizes - List - size dimension (conv_size, embedding_dimension)\n",
    "\n",
    "        #self.embed = nn.Embedding(V, D)                                       # embedding layer\n",
    "        # self.convs1 = [nn.Conv2d(Ci, Co, (K, D)) for K in Ks]\n",
    "        self.convs1 = nn.ModuleList([nn.Conv2d(Ci, Co, (K, D)) for K in Ks])  # List of convolution layer\n",
    "        '''\n",
    "        self.conv13 = nn.Conv2d(Ci, Co, (3, D))\n",
    "        self.conv14 = nn.Conv2d(Ci, Co, (4, D))\n",
    "        self.conv15 = nn.Conv2d(Ci, Co, (5, D))\n",
    "        '''\n",
    "        self.dropout = nn.Dropout(args.dropout)                               # dropout layer\n",
    "        self.fc1 = nn.Linear(len(Ks)*Co, C)                                   # Dense Layer (input dimension, C classes)\n",
    "\n",
    "    def conv_and_pool(self, x, conv):\n",
    "        x = F.relu(conv(x)).squeeze(3)  # (N, Co, W)\n",
    "        x = F.max_pool1d(x, x.size(2)).squeeze(2)\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        #x = self.embed(x)  # (N, W, D)\n",
    "        \n",
    "#         if self.args.static:\n",
    "#             x = Variable(x)\n",
    "\n",
    "        x = x.unsqueeze(1)  # (N, Ci, W, D)\n",
    "\n",
    "        x = [F.relu(conv(x)).squeeze(3) for conv in self.convs1]  # [(N, Co, W), ...]*len(Ks)\n",
    "\n",
    "        x = [F.max_pool1d(i, i.size(2)).squeeze(2) for i in x]  # [(N, Co), ...]*len(Ks)\n",
    "\n",
    "        x = torch.cat(x, 1)\n",
    "\n",
    "        '''\n",
    "        x1 = self.conv_and_pool(x,self.conv13) #(N,Co)\n",
    "        x2 = self.conv_and_pool(x,self.conv14) #(N,Co)\n",
    "        x3 = self.conv_and_pool(x,self.conv15) #(N,Co)\n",
    "        x = torch.cat((x1, x2, x3), 1) # (N,len(Ks)*Co)\n",
    "        '''\n",
    "        x = self.dropout(x)  # (N, len(Ks)*Co)\n",
    "        logit = self.fc1(x)  # (N, C)\n",
    "        return logit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CodeChangeDataset(Dataset):\n",
    "    \"\"\"Face Landmarks dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, X, y, transform = None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            data: dataframe contains features and labels\n",
    "            target_col : target columns name\n",
    "        \"\"\"\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.X.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sentence = self.X[idx]\n",
    "        label = np.asarray(self.y[idx])\n",
    "        sample = {'feature': sentence, 'label': label}\n",
    "\n",
    "        return sample\n",
    "\n",
    "class ToTensor(object):\n",
    "    \"\"\"Convert ndarrays in sample to Tensors.\"\"\"\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        sentence, lable = sample['sentence'], sample['label']\n",
    "        \n",
    "        return {'feature': torch.from_numpy(sentence),\n",
    "                'label': torch.from_numpy(label)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(dataloader, model, args):\n",
    "    model.eval()\n",
    "    corrects, avg_loss = 0, 0\n",
    "    for idx, batch in enumerate(dataloader,0):\n",
    "        feature, target = batch['feature'], batch['label']\n",
    "        if args.cuda:\n",
    "            feature, target = feature.cuda(), target.cuda()\n",
    "\n",
    "        logit = model(feature)\n",
    "        logit = logit.squeeze(1)\n",
    "        loss = F.cross_entropy(logit, target, size_average=False)\n",
    "\n",
    "        avg_loss += loss.item()\n",
    "        corrects += (torch.max(logit, 1)[1].view(target.size()).data == target.data).sum()\n",
    "\n",
    "    size = len(dataloader.dataset)\n",
    "    avg_loss /= size\n",
    "    accuracy = 100.0 * corrects/size\n",
    "    print('Evaluation - loss: {:.6f}  acc: {:.4f}%({}/{}) \\n'.format(avg_loss, accuracy, corrects, size))\n",
    "    return accuracy\n",
    "\n",
    "def train(dataloader, val_dataloader,  model, args):\n",
    "    if args.cuda:\n",
    "        model.cuda()\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=args.lr)\n",
    "    \n",
    "    steps = 0\n",
    "    best_acc = 0\n",
    "    last_step = 0\n",
    "    model.train()\n",
    "    \n",
    "    for epoch in range(1, args.epochs+1):\n",
    "        running_loss = 0.0\n",
    "        for i, batch_data in enumerate(dataloader, 0):\n",
    "             # get the feature and target tensor\n",
    "            feature, target = batch['feature'], batch['label']\n",
    "            if args.cuda:\n",
    "                feature, target = feature.cuda(), target.cuda()\n",
    "            \n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # output : model(input)\n",
    "            output = model(feature)\n",
    "\n",
    "            loss = F.cross_entropy(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            steps += 1\n",
    "            running_loss += loss.item()\n",
    "            \n",
    "        # print training loss - each epoch\n",
    "        # corrects = (torch.max(output, 1)[1].view(target.size()).data == target.data).sum()\n",
    "        # accuracy = 100.0 * corrects/dataloader.batch_size\n",
    "        print('Epoch[{}] - loss: {:.6f}'.format(epoch, running_loss/i))\n",
    "\n",
    "        # evaluation on validation set\n",
    "        dev_acc = eval(val_dataloader, model, args)\n",
    "        if dev_acc > best_acc:\n",
    "            best_acc = dev_acc\n",
    "            last_step = steps\n",
    "#                     if args.save_best:\n",
    "#                         save(model, args.save_dir, 'best', steps)\n",
    "        else:\n",
    "            if steps - last_step >= args.early_stop:\n",
    "                print('early stop by {} steps.'.format(args.early_stop))\n",
    "#             elif steps % args.save_interval == 0:\n",
    "#                 save(model, args.save_dir, 'snapshot', steps)\n",
    "\n",
    "\n",
    "def predict(text, model, text_field, label_feild, cuda_flag):\n",
    "    assert isinstance(text, str)\n",
    "    model.eval()\n",
    "    # text = text_field.tokenize(text)\n",
    "    text = text_field.preprocess(text)\n",
    "    text = [[text_field.vocab.stoi[x] for x in text]]\n",
    "    x = torch.tensor(text)\n",
    "    x = autograd.Variable(x)\n",
    "    if cuda_flag:\n",
    "        x = x.cuda()\n",
    "    print(x)\n",
    "    output = model(x)\n",
    "    _, predicted = torch.max(output, 1)\n",
    "    #return label_feild.vocab.itos[predicted.data[0][0]+1]\n",
    "    return label_feild.vocab.itos[predicted.data[0]+1]\n",
    "\n",
    "\n",
    "# def save(model, save_dir, save_prefix, steps):\n",
    "#     if not os.path.isdir(save_dir):\n",
    "#         os.makedirs(save_dir)\n",
    "#     save_prefix = os.path.join(save_dir, save_prefix)\n",
    "#     save_path = '{}_steps_{}.pt'.format(save_prefix, steps)\n",
    "#     torch.save(model.state_dict(), save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args:\n",
    "    def __init__(self, parameters):\n",
    "        # model parameters\n",
    "        self.lr = parameters['lr'] if parameters.get('lr') != None else 0.001\n",
    "        self.epochs = parameters['epoch'] if parameters.get('epoch') != None else 10\n",
    "        self.batch_size = parameters['batch_size'] if parameters.get('batch_size') != None else 64\n",
    "        self.shuffle = parameters['shuffle'] if parameters.get('shuffle') != None else False                     # whether to shuffle data after every epoch\n",
    "        self.dropout = parameters['dropout'] if parameters.get('dropout') != None else 0.5\n",
    "        self.max_norm = parameters['l2-norm'] if parameters.get('l2-norm') != None else 3.0                      # l2 norm\n",
    "        self.embed_dim = parameters['embed_dim'] if parameters.get('embed_dim') != None else 300                 # embedding dimension\n",
    "        self.embed_num = parameters['embed_num'] if parameters.get('embed_num') != None else 5000               # number of filters for each conv\n",
    "        self.kernel_num = parameters['kernel_num'] if parameters.get('kernel_num') != None else 10               # number of filters for each conv\n",
    "        self.kernel_sizes = parameters['kernel_sizes'] if parameters.get('kernel_sizes') != None else [3,4,5]    # list of kernel sizes\n",
    "        self.class_num = parameters['class_num'] if parameters.get('class_num') != None else 2\n",
    "        \n",
    "        # training precocess parameters\n",
    "        self.log_interval = parameters['log_interval'] if  parameters.get('log_interval') != None else 1\n",
    "        self.test_interval = parameters['test_interval'] if  parameters.get('test_interval') != None else 10\n",
    "        self.save_interval = parameters['save_interval'] if  parameters.get('save_interval') != None else 100\n",
    "        self.save_dir = parameters['save_dir'] if  parameters.get('save_dir') != None else './'\n",
    "        self.early_stop = parameters['early_stop'] if  parameters.get('early_stop') != None else 1000\n",
    "        self.save_best = parameters['save_best'] if  parameters.get('save_best') != None else True\n",
    "        self.no_cuda = parameters['no_cuda'] if  parameters.get('no_cuda') != None else True            # wether to use gpu\n",
    "        self.device = parameters['device'] if  parameters.get('device') != None else -1                 # which device to use -1 means cpu\n",
    "        self.cuda = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[1] - loss: 0.713753\n",
      "Evaluation - loss: 0.668496  acc: 57.0000%(82/143) \n",
      "\n",
      "Epoch[2] - loss: 0.486003\n",
      "Evaluation - loss: 0.634749  acc: 62.0000%(89/143) \n",
      "\n",
      "Epoch[3] - loss: 0.369082\n",
      "Evaluation - loss: 0.623375  acc: 65.0000%(93/143) \n",
      "\n",
      "Epoch[4] - loss: 0.289246\n",
      "Evaluation - loss: 0.624355  acc: 65.0000%(93/143) \n",
      "\n",
      "Epoch[5] - loss: 0.235246\n",
      "Evaluation - loss: 0.633821  acc: 64.0000%(92/143) \n",
      "\n",
      "Epoch[6] - loss: 0.197215\n",
      "Evaluation - loss: 0.647443  acc: 63.0000%(91/143) \n",
      "\n",
      "Epoch[7] - loss: 0.168674\n",
      "Evaluation - loss: 0.663970  acc: 62.0000%(90/143) \n",
      "\n",
      "Epoch[8] - loss: 0.147588\n",
      "Evaluation - loss: 0.682554  acc: 62.0000%(89/143) \n",
      "\n",
      "Epoch[9] - loss: 0.132097\n",
      "Evaluation - loss: 0.702651  acc: 60.0000%(87/143) \n",
      "\n",
      "Epoch[10] - loss: 0.120645\n",
      "Evaluation - loss: 0.724343  acc: 60.0000%(87/143) \n",
      "\n",
      "Epoch[11] - loss: 0.112046\n",
      "Evaluation - loss: 0.745797  acc: 60.0000%(87/143) \n",
      "\n",
      "Epoch[12] - loss: 0.105420\n",
      "Evaluation - loss: 0.766113  acc: 60.0000%(87/143) \n",
      "\n",
      "Epoch[13] - loss: 0.100205\n",
      "Evaluation - loss: 0.785496  acc: 61.0000%(88/143) \n",
      "\n",
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "Exiting from training early\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/queues.py\", line 240, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/queues.py\", line 240, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/queues.py\", line 240, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/queues.py\", line 240, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n"
     ]
    }
   ],
   "source": [
    "parameters = {'class_num':2, 'epoch':20, 'batch_size':64 }\n",
    "args = Args(parameters)\n",
    "\n",
    "# change dir\n",
    "args.save_dir = os.path.join(args.save_dir, datetime.datetime.now().strftime('%Y-%m-%d_%H-%M-%S'))\n",
    "# check gpu avialiable\n",
    "args.cuda = (not args.no_cuda) and torch.cuda.is_available()\n",
    "\n",
    "# data loader\n",
    "train_data = CodeChangeDataset(X_train, y_train, transform = ToTensor())\n",
    "test_data = CodeChangeDataset(X_test, y_test, transform = ToTensor())\n",
    "\n",
    "train_dataloader = DataLoader(train_data, batch_size=args.batch_size,shuffle=True, num_workers=4)\n",
    "test_dataloader = DataLoader(test_data, batch_size=args.batch_size, shuffle = False, num_workers=4)\n",
    "\n",
    "# model\n",
    "cnn = CNN_Text(args)\n",
    "# if args.snapshot is not None:\n",
    "#     print('\\nLoading model from {}...'.format(args.snapshot))\n",
    "#     cnn.load_state_dict(torch.load(args.snapshot))\n",
    "\n",
    "# if args.cuda:\n",
    "#     torch.cuda.set_device(args.device)\n",
    "#     cnn = cnn.cuda()\n",
    "\n",
    "try:\n",
    "    train(train_dataloader, test_dataloader, cnn, args)\n",
    "except KeyboardInterrupt:\n",
    "    print('\\n' + '-' * 89)\n",
    "    print('Exiting from training early')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ichel\\Desktop\\Automatic-Code-Change-Classification\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import sys\n",
    "from simplejson import JSONDecodeError\n",
    "import pprint \n",
    "import math\n",
    "import argparse \n",
    "import os\n",
    "import collections\n",
    "import json\n",
    "import re\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt \n",
    "import random \n",
    "from tensorflow.contrib.tensorboard.plugins import projector\n",
    "from IPython import display\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30465\n",
      "[['INS MethodInvocation to MethodInvocation at 461'], ['INS ExpressionStatement to Block at 8']]\n"
     ]
    }
   ],
   "source": [
    "# parse json to files and actions\n",
    "\n",
    "def parse_json(filepath):\n",
    "    '''\n",
    "    function used to parse json of each commit json file\n",
    "    \n",
    "    Args:\n",
    "        filepath_list - list of filepaths\n",
    "    \n",
    "    Returns:\n",
    "        files_json - list object contains parsed information\n",
    "    \n",
    "    '''\n",
    "    number_of_files = []\n",
    "    files_json = []\n",
    "    \n",
    "    # each commits\n",
    "    files = os.listdir(filepath)\n",
    "    for path in files:\n",
    "        if os.stat(filepath + path).st_size != 0:\n",
    "            with open(filepath + path,'rb') as f:\n",
    "                data = json.load(f)\n",
    "                files_list = []\n",
    "                # each file in commits\n",
    "                for file in data['files']:\n",
    "                    # parse only cluster file\n",
    "                    for key in file.keys():\n",
    "                        if re.match('^.*_cluster$',key):\n",
    "                            actions_list = []\n",
    "                            actions = file[key]['actions']\n",
    "                            # each action in file\n",
    "                            for action in actions:\n",
    "                                actions_list.append(action['root'])\n",
    "                            files_list.append(actions_list)\n",
    "            if len(files_list) != 0: \n",
    "                files_json.append(files_list)\n",
    "    # return\n",
    "    return files_json\n",
    "pwd = os.getcwd()\n",
    "folder_path = pwd + '/AllFiles_Research/'\n",
    "files = parse_json(folder_path)\n",
    "print(len(files))\n",
    "print(files[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "773\n"
     ]
    }
   ],
   "source": [
    "def preprocess_roots(files_data):\n",
    "    counting = {}\n",
    "    for file_index, files in enumerate(files_data):\n",
    "        for root_index, roots in enumerate(files):\n",
    "            for action_index, actions in enumerate(roots):\n",
    "                temp = actions.split(' at ')[0]\n",
    "                tempq = []\n",
    "                if temp.startswith('INS'):\n",
    "                    tempq.append('INS')\n",
    "                    words = [temp.split('INS ')[1].split('to ')[0].strip()\n",
    "                             ] + [temp.split('INS ')[1].split('to ')[-1].strip()]\n",
    "                    for items in words:\n",
    "\n",
    "                        items = items.split(': ')[0]\n",
    "                        tempq.append(items)\n",
    "                    temp = '_'.join(tempq)\n",
    "\n",
    "                if temp.startswith('UPDATE'):\n",
    "                    temp = 'UPDATE'\n",
    "                if temp.startswith('MOVE'):\n",
    "                    temp2 = temp.split(' from ')[1]\n",
    "                    tempq.append('MOVE')\n",
    "                    tempq.append(temp2.split(': ')[0])\n",
    "                    temp = '_'.join(tempq)\n",
    "\n",
    "                if temp.startswith('DEL'):\n",
    "                    tempq.append('DEL')\n",
    "                    tempq.append(temp.split('DEL ')[1].split(': ')[0])\n",
    "                    temp = '_'.join(tempq)\n",
    "                counting[temp] = counting.get(temp, 0) + 1\n",
    "                files_data[file_index][root_index][action_index] = temp\n",
    "    dic = {}\n",
    "    i = 0\n",
    "    for k, v in counting.items():\n",
    "        dic[k] = i  \n",
    "        i += 1\n",
    "    return dic, files_data, counting \n",
    "\n",
    "dic, datas, freq_dict = preprocess_roots(files)\n",
    "print(len(dic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f83320cbcf8>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def actions2sentence(datas):\n",
    "    data_total = []\n",
    "    for files in datas:\n",
    "        data4file = []\n",
    "        for roots in files:\n",
    "            sentence = ' '.join(roots)\n",
    "            data4file.append(sentence)\n",
    "        data_total.append(data4file)\n",
    "    return data_total\n",
    "\n",
    "\n",
    "training_data = actions2sentence(datas)\n",
    "\n",
    "def get_seqlength(training_data):\n",
    "    max_root_len = 0\n",
    "    seqlength_list = []\n",
    "    for items in training_data:\n",
    "        for item in items:\n",
    "            seqlength_list.append(len(item.split(\" \")))\n",
    "            if len(item.split(\" \")) >  max_root_len: \n",
    "                max_root_len = len(item.split(\" \"))\n",
    "    return max_root_len, seqlength_list\n",
    "\n",
    "def plot_hist(seqlength_list): \n",
    "    plt.figure(figsize=(20,10))\n",
    "    number_of_files = np.array(seqlength_list)\n",
    "    bincount = np.bincount(seqlength_list)\n",
    "    x = np.arange(1, len(bincount)+1)\n",
    "    n, bins, patches = plt.hist(seqlength_list,x)\n",
    "\n",
    "max_seqlength, sequence_list = get_seqlength(training_data)\n",
    "plot_hist(sequence_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['INS_IfStatement_Block UPDATE MOVE_Block']\n"
     ]
    }
   ],
   "source": [
    "print(training_data[0]) # output is a single commit "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Global variable \n",
    "data_id = 0\n",
    "def word2vec_basic(log_dir, dic, freq_dict, training_data):\n",
    "    \"\"\" Word2vec model \"\"\"\n",
    "    # Create the directory for TensorBoard variables if there is not.\n",
    "    \n",
    "    if not os.path.exists(log_dir):\n",
    "        os.makedirs(log_dir)\n",
    "    # Generate reverse dictionary from dictionary \n",
    "    rev_dic = dict(zip(dic.values(), dic.keys()))\n",
    "    \n",
    "    def concat_train_data(training_data): \n",
    "        concat_data = \"\"\n",
    "        tmp_list = []\n",
    "        for items in training_data: \n",
    "            tmp_list += items\n",
    "        concat_data = \" \".join(tmp_list)\n",
    "        return concat_data\n",
    "    \n",
    "    def tokenize_train_data(concat_train_data): \n",
    "        data = []\n",
    "        for word in concat_train_data.split(): \n",
    "            index = dic.get(word)\n",
    "            data.append(index)\n",
    "        return data  \n",
    "            \n",
    "    \n",
    "    # Generate batch for skip-gram model: \n",
    "    def generate_batch(batch_size, num_skips, skip_window): \n",
    "        global data_id \n",
    "        assert batch_size % num_skips == 0\n",
    "        assert num_skips <= 2 * skip_window \n",
    "        batch = np.ndarray(shape=(batch_size), dtype=np.int32)\n",
    "        labels = np.ndarray(shape=(batch_size, 1), dtype=np.int32)\n",
    "        span = 2 * skip_window + 1  # context of a word \n",
    "        buffer = collections.deque(maxlen=span)  # pylint: disable=redefined-builtin\n",
    "        \n",
    "        # get concatenated data \n",
    "        data = concat_train_data(training_data)\n",
    "        data = tokenize_train_data(data)  # convert root to is index \n",
    "        \n",
    "        if data_id + span > len(data):\n",
    "            data_id = 0\n",
    "        buffer.extend(data[data_id:data_id + span])\n",
    "        data_id += span\n",
    "        for i in range(batch_size // num_skips):\n",
    "            # all range of words that are not equal to window size\n",
    "            context_words = [w for w in range(span) if w != skip_window] \n",
    "            words_to_use = random.sample(context_words, num_skips)\n",
    "            for j, context_word in enumerate(words_to_use):\n",
    "                batch[i * num_skips + j] = buffer[skip_window]\n",
    "                labels[i * num_skips + j, 0] = buffer[context_word]\n",
    "            if data_id == len(data):\n",
    "                buffer.extend(data[0:span])\n",
    "                data_id = span\n",
    "            else:\n",
    "                buffer.append(data[data_id])\n",
    "                data_id += 1\n",
    "            # Backtrack a little bit to avoid skipping words in the end of a batch\n",
    "        data_id = (data_id + len(data) - span) % len(data)\n",
    "        return batch, labels\n",
    "\n",
    "    batch, labels = generate_batch(batch_size=8, num_skips=2, skip_window=1)\n",
    "    for i in range(8): \n",
    "        print(batch[i], rev_dic[batch[i]], '->', labels[i, 0], rev_dic[labels[i, 0]])\n",
    "        \n",
    "    # Build and train skip-gram model. \n",
    "    \n",
    "    #Hyperparameters \n",
    "    batch_size = 128\n",
    "    embedding_size = 128  # Dimension of the embedding vector.\n",
    "    skip_window = 1   # How many words to consider left and right.\n",
    "    num_skips = 2     # How many times to reuse an input to generate a label.\n",
    "    num_sampled = 64  # Number of negative examples to sample.\n",
    "    keep_prob = 0.4 # Dropout rate \n",
    "    learning_rate = 0.05\n",
    "    \n",
    "    #Select random sample of most frequent words for model validation \n",
    "    valid_size = 16  # Random set of words to evaluate similarity on.\n",
    "    valid_window = 100  # Only pick dev samples in the head of the distribution.\n",
    "    valid_examples = np.random.choice(valid_window, valid_size, replace=False)\n",
    "    \n",
    "    graph = tf.Graph()\n",
    "    \n",
    "    with graph.as_default(): \n",
    "        #input data \n",
    "        with tf.name_scope('inputs'): \n",
    "            train_inputs = tf.placeholder(tf.int32, shape=[batch_size])\n",
    "            train_labels = tf.placeholder(tf.int32, shape=[batch_size, 1])\n",
    "            valid_dataset = tf.constant(valid_examples, dtype=tf.int32)\n",
    "        #ops and variables pinned to the CPU because of missing GPU implementation \n",
    "        with tf.device('/cpu:0'): \n",
    "            #Implement dropout \n",
    "            with tf.name_scope(\"embedding_dropout\"):\n",
    "                embeddings = tf.Variable(tf.random_uniform([len(dic), embedding_size], -1.0, 1.0))\n",
    "                embeddings = tf.nn.dropout(embeddings, rate=1 - keep_prob, noise_shape=[len(dic), 1])\n",
    "            #Look up embeddings for inputs \n",
    "            with tf.name_scope('embeddings'): \n",
    "                embed = tf.nn.embedding_lookup(embeddings, train_inputs)\n",
    "                #Construct the variables for the NCE loss \n",
    "            with tf.name_scope('weights'): \n",
    "                nce_weights = tf.Variable(tf.truncated_normal([len(dic), embedding_size], stddev=1.0/math.sqrt(embedding_size)))\n",
    "            with tf.name_scope('biases'): \n",
    "                nce_biases = tf.Variable(tf.zeros([len(dic)]))\n",
    "        # Compute the average NCE loss for the batch.\n",
    "        # tf.nce_loss automatically draws a new sample of the negative labels each\n",
    "        # time we evaluate the loss.\n",
    "        # Explanation of the meaning of NCE loss:\n",
    "        # http://mccormickml.com/2016/04/19/word2vec-tutorial-the-skip-gram-model/        \n",
    "        with tf.name_scope('loss'): \n",
    "            loss = tf.reduce_mean(\n",
    "                tf.nn.nce_loss(\n",
    "                    weights=nce_weights, \n",
    "                    biases=nce_biases, \n",
    "                    labels=train_labels, \n",
    "                    inputs=embed, \n",
    "                    num_sampled=num_sampled, \n",
    "                    num_classes=len(dic)\n",
    "                )\n",
    "            )\n",
    "        #Add the loss value as a scaler to the summary. \n",
    "        tf.summary.scalar(\"loss\", loss)\n",
    "        #Construct the SGD optimizer using a learninig rate of 1.0 \n",
    "        with tf.name_scope('optimizer'): \n",
    "            optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss)\n",
    "        # Compute the cosine similarity between minibatch examples and all\n",
    "        # embeddings.\n",
    "        norm = tf.sqrt(tf.reduce_sum(tf.square(embeddings), 1, keepdims=True))\n",
    "        normalized_embeddings = embeddings / norm\n",
    "        valid_embeddings = tf.nn.embedding_lookup(normalized_embeddings, valid_dataset)\n",
    "        similarity = tf.matmul(valid_embeddings, normalized_embeddings, transpose_b=True)\n",
    "        # Merge all summaries.\n",
    "        merged = tf.summary.merge_all()\n",
    "        # Add variable initializer.\n",
    "        init = tf.global_variables_initializer()\n",
    "        # Create a saver.\n",
    "        saver = tf.train.Saver()\n",
    "        \n",
    "        \n",
    "        \n",
    "    # Step 5: Begin training.\n",
    "    num_steps = 10000\n",
    "    \n",
    "    with tf.compat.v1.Session(graph=graph) as session: \n",
    "        #open a writer to write summaries \n",
    "        writer = tf.summary.FileWriter(log_dir, session.graph)\n",
    "        #We must initialize all variables before we use them. \n",
    "        init.run()\n",
    "        print('Initialized')\n",
    "        average_loss = 0\n",
    "        avg_loss_list = []\n",
    "        steps_list = []\n",
    "        for step in range(num_steps): \n",
    "            batch_inputs, batch_labels = generate_batch(batch_size, num_skips, skip_window)\n",
    "            feed_dict = {train_inputs: batch_inputs, train_labels: batch_labels}\n",
    "            # Define metadata variable.\n",
    "            run_metadata = tf.RunMetadata()\n",
    "            # We perform one update step by evaluating the optimizer op (including it\n",
    "            # in the list of returned values for session.run()\n",
    "            # Also, evaluate the merged op to get all summaries from the returned\n",
    "            # \"summary\" variable. Feed metadata variable to session for visualizing\n",
    "            # the graph in TensorBoard.\n",
    "            _, summary, loss_val = session.run([optimizer, merged, loss], feed_dict=feed_dict, run_metadata=run_metadata)\n",
    "            average_loss += loss_val \n",
    "            #Add returned summaries to writer in each step. \n",
    "            writer.add_summary(summary, step)\n",
    "            #Add metadata to visualize the graph for the last run. \n",
    "            if step == (num_steps - 1):\n",
    "                writer.add_run_metadata(run_metadata, 'step%d' % step) \n",
    "            if step % 200 == 0: \n",
    "                if step > 0: \n",
    "                    average_loss /= 200 \n",
    "                    avg_loss_list.append(average_loss)\n",
    "                    steps_list.append(step)\n",
    "                # The average loss is an estimate of the loss over the last 2000\n",
    "                # batches.\n",
    "                print('Average loss at step ', step, ': ', average_loss)\n",
    "                average_loss = 0 \n",
    "            #Note that this is expensive (~20% slowdown if computed every 500 steps)\n",
    "            if step % 10000 == 0: \n",
    "                sim = similarity.eval()\n",
    "                for i in range(valid_size): \n",
    "                    valid_word = rev_dic[valid_examples[i]]\n",
    "                    top_k = 8  # number of nearest neighbors\n",
    "                    nearest = (-sim[i, :]).argsort()[1:top_k + 1]\n",
    "                    log_str = 'Nearest to %s:' % valid_word\n",
    "                    for k in range(top_k):\n",
    "                        close_word = rev_dic[nearest[k]]\n",
    "                        log_str = '%s %s,' % (log_str, close_word)\n",
    "                    #print(log_str)\n",
    "                    #print(\"\\n\")\n",
    "            final_embeddings = normalized_embeddings.eval()\n",
    "            #Write corresponding labels for the embeddings\n",
    "            with open(log_dir + '/metadata.tsv', 'w') as f:\n",
    "                for i in range(len(dic)): \n",
    "                    f.write(rev_dic[i] + '\\n')\n",
    "            # Save the model for chpts \n",
    "            saver.save(session, os.path.join(log_dir, 'model.ckpt'))\n",
    "            # Create a configuration for visualizing embeddings with the labels in\n",
    "            # TensorBoard.\n",
    "            config = projector.ProjectorConfig()\n",
    "            embedding_conf = config.embeddings.add()\n",
    "            embedding_conf.tensor_name = embeddings.name\n",
    "            embedding_conf.metadata_path = os.path.join(log_dir, 'metadata.tsv')\n",
    "            projector.visualize_embeddings(writer, config)\n",
    "        writer.close()\n",
    "        return avg_loss_list, steps_list\n",
    "# #         Step 6: Visualize the embeddings.\n",
    "# #         pylint: disable=missing-docstring\n",
    "# #         Function to draw visualization of distance between embeddings.\n",
    "# #         def plot_with_labels(low_dim_embs, labels, filename):\n",
    "#             assert low_dim_embs.shape[0] >= len(labels), 'More labels than embeddings'\n",
    "#             plt.figure(figsize=(18, 18))  # in inches\n",
    "#             for i, label in enumerate(labels):\n",
    "#                 x, y = low_dim_embs[i, :]\n",
    "#                 plt.scatter(x, y)\n",
    "#                 plt.annotate(\n",
    "#                     label,\n",
    "#                     xy=(x, y),\n",
    "#                     xytext=(5, 2),\n",
    "#                     textcoords='offset points',\n",
    "#                     ha='right',\n",
    "#                     va='bottom')\n",
    "#                 plt.savefig(filename)\n",
    "#         try:\n",
    "#             # pylint: disable=g-import-not-at-top\n",
    "#             from sklearn.manifold import TSNE\n",
    "#             import matplotlib.pyplot as plt\n",
    "#             tsne = TSNE(\n",
    "#                 perplexity=30, n_components=2, init='pca', n_iter=5000, method='exact')\n",
    "#             plot_only = 500\n",
    "#             low_dim_embs = tsne.fit_transform(final_embeddings[:plot_only, :])\n",
    "#             labels = [rev_dic[i] for i in range(plot_only)]\n",
    "#             plot_with_labels(low_dim_embs, labels, os.path.join(gettempdir(), 'tsne.png'))\n",
    "#         except ImportError as ex:\n",
    "#             print('Please install sklearn, matplotlib, and scipy to show embeddings.')\n",
    "#             print(ex)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0718 23:04:16.087703 140202488821568 nn_ops.py:4224] Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 UPDATE -> 2 MOVE_Block\n",
      "1 UPDATE -> 0 INS_IfStatement_Block\n",
      "2 MOVE_Block -> 3 INS_MethodInvocation_MethodInvocation\n",
      "2 MOVE_Block -> 1 UPDATE\n",
      "3 INS_MethodInvocation_MethodInvocation -> 2 MOVE_Block\n",
      "3 INS_MethodInvocation_MethodInvocation -> 4 INS_ExpressionStatement_Block\n",
      "4 INS_ExpressionStatement_Block -> 5 INS_ImportDeclaration_CompilationUnit\n",
      "4 INS_ExpressionStatement_Block -> 3 INS_MethodInvocation_MethodInvocation\n",
      "Initialized\n",
      "Average loss at step  0 :  141.03851318359375\n",
      "Average loss at step  200 :  96.98401834487915\n",
      "Average loss at step  400 :  64.84839018821717\n",
      "Average loss at step  600 :  52.444410486221315\n",
      "Average loss at step  800 :  44.28541670799255\n",
      "Average loss at step  1000 :  38.85719943165779\n",
      "Average loss at step  1200 :  34.65189269542694\n",
      "Average loss at step  1400 :  32.365451228618625\n",
      "Average loss at step  1600 :  28.30774120092392\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-55-5b82b68212c7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/platform/app.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(main, argv)\u001b[0m\n\u001b[1;32m     38\u001b[0m   \u001b[0mmain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmain\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_sys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'__main__'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m   \u001b[0m_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags_parser\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_parse_flags_tolerate_undef\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/absl/app.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(main, argv, flags_parser)\u001b[0m\n\u001b[1;32m    298\u001b[0m       \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 300\u001b[0;31m       \u001b[0m_run_main\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    301\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mUsageError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m       \u001b[0musage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshorthelp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdetailed_error\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexitcode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexitcode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/absl/app.py\u001b[0m in \u001b[0;36m_run_main\u001b[0;34m(main, argv)\u001b[0m\n\u001b[1;32m    249\u001b[0m     \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m     \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-55-5b82b68212c7>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(unused_argv)\u001b[0m\n\u001b[1;32m     14\u001b[0m         help='The log directory for TensorBoard summaries.')\n\u001b[1;32m     15\u001b[0m     \u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munused_flags\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_known_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mavg_loss_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mword2vec_basic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfreq_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mavg_loss_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-54-15cf1b87afd2>\u001b[0m in \u001b[0;36mword2vec_basic\u001b[0;34m(log_dir, dic, freq_dict, training_data)\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0msteps_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m             \u001b[0mbatch_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_skips\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip_window\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    155\u001b[0m             \u001b[0mfeed_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mtrain_inputs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_labels\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m             \u001b[0;31m# Define metadata variable.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-54-15cf1b87afd2>\u001b[0m in \u001b[0;36mgenerate_batch\u001b[0;34m(batch_size, num_skips, skip_window)\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0;31m# get concatenated data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconcat_train_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenize_train_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# convert root to is index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdata_id\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mspan\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-54-15cf1b87afd2>\u001b[0m in \u001b[0;36mtokenize_train_data\u001b[0;34m(concat_train_data)\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mconcat_train_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# All functionality is run after tf.compat.v1.app.run() (b/122547914). This\n",
    "# could be split up but the methods are laid sequentially with their usage for\n",
    "# clarity.\n",
    "def main(unused_argv):\n",
    "  # Give a folder path as an argument with '--log_dir' to save\n",
    "  # TensorBoard summaries. Default is a log folder in current directory.\n",
    "    current_path = os.path.dirname(os.path.realpath(sys.argv[0]))\n",
    "\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\n",
    "        '--log_dir',\n",
    "        type=str,\n",
    "        default=os.path.join(current_path, 'log'),\n",
    "        help='The log directory for TensorBoard summaries.')\n",
    "    flags, unused_flags = parser.parse_known_args()\n",
    "    avg_loss_list, steps_list = word2vec_basic(flags.log_dir, dic, freq_dict, training_data)\n",
    "    plt.figure(figsize=(20, 20))\n",
    "    plt.plot(avg_loss_list, steps_list)\n",
    "    plt.title(\"Avg Loss\")\n",
    "    plt.xlabel(\"epochs\")\n",
    "    plt.ylabel(\"loss\")\n",
    "    plt.show()\n",
    "if __name__ == '__main__':\n",
    "    tf.app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

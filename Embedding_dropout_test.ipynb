{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import sys\n",
    "from simplejson import JSONDecodeError\n",
    "import pprint \n",
    "import math\n",
    "import argparse \n",
    "import os\n",
    "import collections\n",
    "import json\n",
    "import re\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt \n",
    "import random \n",
    "from tensorflow.contrib.tensorboard.plugins import projector\n",
    "from IPython import display\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30465\n",
      "[['DEL ExpressionStatement', 'DEL ExpressionStatement'], ['UPDATE from DEFAULT_SESSION_ID_COOKIE_NAME to DEFAULT_SESSION_ID_KEY_NAME', 'INS NullLiteral to VariableDeclarationFragment at 1', 'INS VariableDeclarationStatement to Block at 1', 'UPDATE from idStore to store', 'INS IfStatement to Block at 0', 'INS ExpressionStatement to Block at 1', 'MOVE from Assignment: =', 'UPDATE from IllegalStateException to HttpSessionStore', 'MOVE from SimpleType: HttpSessionStore', 'DEL VariableDeclarationStatement', 'DEL ThrowStatement'], ['INS InfixExpression: && to IfStatement at 0', 'MOVE from InfixExpression: &&', 'UPDATE from isInfoEnabled to isDebugEnabled', 'UPDATE from info to debug'], ['INS FieldDeclaration to TypeDeclaration: class at 13', 'INS MethodDeclaration to TypeDeclaration: class at 27', 'INS MethodDeclaration to TypeDeclaration: class at 28', 'MOVE from Block', 'INS InfixExpression: && to ReturnStatement at 0', 'INS ExpressionStatement to Block at 3', 'MOVE from InfixExpression: &&', 'DEL ExpressionStatement', 'DEL SimpleName: value', 'DEL IfStatement']]\n"
     ]
    }
   ],
   "source": [
    "# parse json to files and actions\n",
    "\n",
    "def parse_json(filepath):\n",
    "    '''\n",
    "    function used to parse json of each commit json file\n",
    "    \n",
    "    Args:\n",
    "        filepath_list - list of filepaths\n",
    "    \n",
    "    Returns:\n",
    "        files_json - list object contains parsed information\n",
    "    \n",
    "    '''\n",
    "    number_of_files = []\n",
    "    files_json = []\n",
    "    \n",
    "    # each commits\n",
    "    files = os.listdir(filepath)\n",
    "    for path in files:\n",
    "        if os.stat(filepath + path).st_size != 0 and path != 'desktop.ini':\n",
    "            with open(filepath + path, encoding=\"utf8\") as f:\n",
    "                data = json.load(f)\n",
    "                files_list = []\n",
    "                # each file in commits\n",
    "                for file in data['files']:\n",
    "                    # parse only cluster file\n",
    "                    for key in file.keys():\n",
    "                        if re.match('^.*_cluster$',key):\n",
    "                            actions_list = []\n",
    "                            actions = file[key]['actions']\n",
    "                            # each action in file\n",
    "                            for action in actions:\n",
    "                                actions_list.append(action['root'])\n",
    "                            files_list.append(actions_list)\n",
    "            if len(files_list) != 0: \n",
    "                files_json.append(files_list)\n",
    "    # return\n",
    "    return files_json\n",
    "folder_path = 'C:\\\\Users\\\\ichel\\\\Desktop\\\\shared_ReFiles\\\\AllFiles_Research\\\\'\n",
    "files = parse_json(folder_path)\n",
    "print(len(files))\n",
    "print(files[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "773\n"
     ]
    }
   ],
   "source": [
    "def preprocess_roots(files_data):\n",
    "    counting = {}\n",
    "    for file_index, files in enumerate(files_data):\n",
    "        for root_index, roots in enumerate(files):\n",
    "            for action_index, actions in enumerate(roots):\n",
    "                temp = actions.split(' at ')[0]\n",
    "                tempq = []\n",
    "                if temp.startswith('INS'):\n",
    "                    tempq.append('INS')\n",
    "                    words = [temp.split('INS ')[1].split('to ')[0].strip()\n",
    "                             ] + [temp.split('INS ')[1].split('to ')[-1].strip()]\n",
    "                    for items in words:\n",
    "\n",
    "                        items = items.split(': ')[0]\n",
    "                        tempq.append(items)\n",
    "                    temp = '_'.join(tempq)\n",
    "\n",
    "                if temp.startswith('UPDATE'):\n",
    "                    temp = 'UPDATE'\n",
    "                if temp.startswith('MOVE'):\n",
    "                    temp2 = temp.split(' from ')[1]\n",
    "                    tempq.append('MOVE')\n",
    "                    tempq.append(temp2.split(': ')[0])\n",
    "                    temp = '_'.join(tempq)\n",
    "\n",
    "                if temp.startswith('DEL'):\n",
    "                    tempq.append('DEL')\n",
    "                    tempq.append(temp.split('DEL ')[1].split(': ')[0])\n",
    "                    temp = '_'.join(tempq)\n",
    "                counting[temp] = counting.get(temp, 0) + 1\n",
    "                files_data[file_index][root_index][action_index] = temp\n",
    "    dic = {}\n",
    "    i = 0\n",
    "    for k, v in counting.items():\n",
    "        dic[k] = i  \n",
    "        i += 1\n",
    "    return dic, files_data, counting \n",
    "\n",
    "dic, datas, freq_dict = preprocess_roots(files)\n",
    "print(len(dic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def actions2sentence(datas):\n",
    "    data_total = []\n",
    "    for files in datas:\n",
    "        data4file = []\n",
    "        for roots in files:\n",
    "            sentence = ' '.join(roots)\n",
    "            data4file.append(sentence)\n",
    "        data_total.append(data4file)\n",
    "    return data_total\n",
    "\n",
    "\n",
    "training_data = actions2sentence(datas)\n",
    "\n",
    "def get_seqlength(training_data):\n",
    "    max_root_len = 0\n",
    "    seqlength_list = []\n",
    "    for items in training_data:\n",
    "        for item in items:\n",
    "            seqlength_list.append(len(item.split(\" \")))\n",
    "            if len(item.split(\" \")) >  max_root_len: \n",
    "                max_root_len = len(item.split(\" \"))\n",
    "    return max_root_len, seqlength_list\n",
    "\n",
    "def plot_hist(seqlength_list): \n",
    "    plt.figure(figsize=(20,10))\n",
    "    number_of_files = np.array(seqlength_list)\n",
    "    bincount = np.bincount(seqlength_list)\n",
    "    x = np.arange(1, len(bincount)+1)\n",
    "    n, bins, patches = plt.hist(seqlength_list,x)\n",
    "\n",
    "max_seqlength, sequence_list = get_seqlength(training_data)\n",
    "plot_hist(sequence_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['INS_ImportDeclaration_CompilationUnit INS_SingleVariableDeclaration_MethodDeclaration INS_SingleVariableDeclaration_MethodDeclaration INS_TagElement_Javadoc INS_TagElement_Javadoc', 'INS_SingleVariableDeclaration_MethodDeclaration INS_SingleVariableDeclaration_MethodDeclaration INS_VariableDeclarationStatement_Block INS_VariableDeclarationStatement_Block INS_ExpressionStatement_Block INS_ExpressionStatement_Block INS_SimpleName_ReturnStatement MOVE_VariableDeclarationFragment', 'INS_SimpleName_MethodInvocation INS_SimpleName_MethodInvocation INS_SimpleName_MethodInvocation']\n"
     ]
    }
   ],
   "source": [
    "print(training_data[0]) # output is a single commit "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Global variable \n",
    "data_id = 0\n",
    "def word2vec_basic(log_dir, dic, freq_dict, training_data):\n",
    "    \"\"\" Word2vec model \"\"\"\n",
    "    # Create the directory for TensorBoard variables if there is not.\n",
    "    \n",
    "    if not os.path.exists(log_dir):\n",
    "        os.makedirs(log_dir)\n",
    "    # Generate reverse dictionary from dictionary \n",
    "    rev_dic = dict(zip(dic.values(), dic.keys()))\n",
    "    \n",
    "    def concat_train_data(training_data): \n",
    "        concat_data = \"\"\n",
    "        tmp_list = []\n",
    "        for items in training_data: \n",
    "            tmp_list += items\n",
    "        concat_data = \" \".join(tmp_list)\n",
    "        return concat_data\n",
    "    \n",
    "    def tokenize_train_data(concat_train_data): \n",
    "        data = []\n",
    "        for word in concat_train_data.split(): \n",
    "            index = dic.get(word)\n",
    "            data.append(index)\n",
    "        return data  \n",
    "            \n",
    "    \n",
    "    # Generate batch for skip-gram model: \n",
    "    def generate_batch(batch_size, num_skips, skip_window): \n",
    "        global data_id \n",
    "        assert batch_size % num_skips == 0\n",
    "        assert num_skips <= 2 * skip_window \n",
    "        batch = np.ndarray(shape=(batch_size), dtype=np.int32)\n",
    "        labels = np.ndarray(shape=(batch_size, 1), dtype=np.int32)\n",
    "        span = 2 * skip_window + 1  # context of a word \n",
    "        buffer = collections.deque(maxlen=span)  # pylint: disable=redefined-builtin\n",
    "        \n",
    "        # get concatenated data \n",
    "        data = concat_train_data(training_data)\n",
    "        data = tokenize_train_data(data)  # convert root to is index \n",
    "        \n",
    "        if data_id + span > len(data):\n",
    "            data_id = 0\n",
    "        buffer.extend(data[data_id:data_id + span])\n",
    "        data_id += span\n",
    "        for i in range(batch_size // num_skips):\n",
    "            # all range of words that are not equal to window size\n",
    "            context_words = [w for w in range(span) if w != skip_window] \n",
    "            words_to_use = random.sample(context_words, num_skips)\n",
    "            for j, context_word in enumerate(words_to_use):\n",
    "                batch[i * num_skips + j] = buffer[skip_window]\n",
    "                labels[i * num_skips + j, 0] = buffer[context_word]\n",
    "            if data_id == len(data):\n",
    "                buffer.extend(data[0:span])\n",
    "                data_id = span\n",
    "            else:\n",
    "                buffer.append(data[data_id])\n",
    "                data_id += 1\n",
    "            # Backtrack a little bit to avoid skipping words in the end of a batch\n",
    "        data_id = (data_id + len(data) - span) % len(data)\n",
    "        return batch, labels\n",
    "\n",
    "    batch, labels = generate_batch(batch_size=8, num_skips=2, skip_window=1)\n",
    "    for i in range(8): \n",
    "        print(batch[i], rev_dic[batch[i]], '->', labels[i, 0], rev_dic[labels[i, 0]])\n",
    "        \n",
    "    # Build and train skip-gram model. \n",
    "    \n",
    "    #Hyperparameters \n",
    "    batch_size = 128\n",
    "    embedding_size = 128  # Dimension of the embedding vector.\n",
    "    skip_window = 1   # How many words to consider left and right.\n",
    "    num_skips = 2     # How many times to reuse an input to generate a label.\n",
    "    num_sampled = 64  # Number of negative examples to sample.\n",
    "    rate = 0.4 # Dropout rate \n",
    "    learning_rate = 0.05\n",
    "    \n",
    "    #Select random sample of most frequent words for model validation \n",
    "    valid_size = 16  # Random set of words to evaluate similarity on.\n",
    "    valid_window = 100  # Only pick dev samples in the head of the distribution.\n",
    "    valid_examples = np.random.choice(valid_window, valid_size, replace=False)\n",
    "    \n",
    "    graph = tf.Graph()\n",
    "    \n",
    "    with graph.as_default(): \n",
    "        #input data \n",
    "        with tf.name_scope('inputs'): \n",
    "            train_inputs = tf.placeholder(tf.int32, shape=[batch_size])\n",
    "            train_labels = tf.placeholder(tf.int32, shape=[batch_size, 1])\n",
    "            valid_dataset = tf.constant(valid_examples, dtype=tf.int32)\n",
    "        #ops and variables pinned to the CPU because of missing GPU implementation \n",
    "        with tf.device(\"gpu:0\"): \n",
    "            #Implement dropout \n",
    "            with tf.name_scope(\"embedding_dropout\"):\n",
    "                embeddings = tf.Variable(tf.random_uniform([len(dic), embedding_size], -1.0, 1.0))\n",
    "                embeddings = tf.nn.dropout(embeddings, keep_prob=1 - rate, noise_shape=[len(dic), 1])\n",
    "            #Look up embeddings for inputs \n",
    "            with tf.name_scope('embeddings'): \n",
    "                embed = tf.nn.embedding_lookup(embeddings, train_inputs)\n",
    "                #Construct the variables for the NCE loss \n",
    "            with tf.name_scope('weights'): \n",
    "                nce_weights = tf.Variable(tf.truncated_normal([len(dic), embedding_size], stddev=1.0/math.sqrt(embedding_size)))\n",
    "            with tf.name_scope('biases'): \n",
    "                nce_biases = tf.Variable(tf.zeros([len(dic)]))\n",
    "        # Compute the average NCE loss for the batch.\n",
    "        # tf.nce_loss automatically draws a new sample of the negative labels each\n",
    "        # time we evaluate the loss.\n",
    "        # Explanation of the meaning of NCE loss:\n",
    "        # http://mccormickml.com/2016/04/19/word2vec-tutorial-the-skip-gram-model/        \n",
    "        with tf.name_scope('loss'): \n",
    "            loss = tf.reduce_mean(\n",
    "                tf.nn.nce_loss(\n",
    "                    weights=nce_weights, \n",
    "                    biases=nce_biases, \n",
    "                    labels=train_labels, \n",
    "                    inputs=embed, \n",
    "                    num_sampled=num_sampled, \n",
    "                    num_classes=len(dic)\n",
    "                )\n",
    "            )\n",
    "        #Add the loss value as a scaler to the summary. \n",
    "        tf.summary.scalar(\"loss\", loss)\n",
    "        #Construct the SGD optimizer using a learninig rate of 1.0 \n",
    "        with tf.name_scope('optimizer'): \n",
    "            optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss)\n",
    "        # Compute the cosine similarity between minibatch examples and all\n",
    "        # embeddings.\n",
    "        norm = tf.sqrt(tf.reduce_sum(tf.square(embeddings), 1, keepdims=True))\n",
    "        normalized_embeddings = embeddings / norm\n",
    "        valid_embeddings = tf.nn.embedding_lookup(normalized_embeddings, valid_dataset)\n",
    "        similarity = tf.matmul(valid_embeddings, normalized_embeddings, transpose_b=True)\n",
    "        # Merge all summaries.\n",
    "        merged = tf.summary.merge_all()\n",
    "        # Add variable initializer.\n",
    "        init = tf.global_variables_initializer()\n",
    "        # Create a saver.\n",
    "        saver = tf.train.Saver()\n",
    "        \n",
    "        \n",
    "        \n",
    "    # Step 5: Begin training.\n",
    "    num_steps = 10000\n",
    "    \n",
    "    with tf.compat.v2.Session(graph=graph) as session: \n",
    "        #open a writer to write summaries \n",
    "        writer = tf.summary.FileWriter(log_dir, session.graph)\n",
    "        #We must initialize all variables before we use them. \n",
    "        init.run()\n",
    "        print('Initialized')\n",
    "        average_loss = 0\n",
    "        avg_loss_list = []\n",
    "        steps_list = []\n",
    "        for step in range(num_steps): \n",
    "            batch_inputs, batch_labels = generate_batch(batch_size, num_skips, skip_window)\n",
    "            feed_dict = {train_inputs: batch_inputs, train_labels: batch_labels}\n",
    "            # Define metadata variable.\n",
    "            run_metadata = tf.RunMetadata()\n",
    "            # We perform one update step by evaluating the optimizer op (including it\n",
    "            # in the list of returned values for session.run()\n",
    "            # Also, evaluate the merged op to get all summaries from the returned\n",
    "            # \"summary\" variable. Feed metadata variable to session for visualizing\n",
    "            # the graph in TensorBoard.\n",
    "            _, summary, loss_val = session.run([optimizer, merged, loss], feed_dict=feed_dict, run_metadata=run_metadata)\n",
    "            average_loss += loss_val \n",
    "            #Add returned summaries to writer in each step. \n",
    "            writer.add_summary(summary, step)\n",
    "            #Add metadata to visualize the graph for the last run. \n",
    "            if step == (num_steps - 1):\n",
    "                writer.add_run_metadata(run_metadata, 'step%d' % step) \n",
    "            if step % 200 == 0: \n",
    "                if step > 0: \n",
    "                    average_loss /= 200 \n",
    "                    avg_loss_list.append(average_loss)\n",
    "                    steps_list.append(step)\n",
    "                # The average loss is an estimate of the loss over the last 2000\n",
    "                # batches.\n",
    "                print('Average loss at step ', step, ': ', average_loss)\n",
    "                average_loss = 0 \n",
    "            #Note that this is expensive (~20% slowdown if computed every 500 steps)\n",
    "            if step % 10000 == 0: \n",
    "                sim = similarity.eval()\n",
    "                for i in range(valid_size): \n",
    "                    valid_word = rev_dic[valid_examples[i]]\n",
    "                    top_k = 8  # number of nearest neighbors\n",
    "                    nearest = (-sim[i, :]).argsort()[1:top_k + 1]\n",
    "                    log_str = 'Nearest to %s:' % valid_word\n",
    "                    for k in range(top_k):\n",
    "                        close_word = rev_dic[nearest[k]]\n",
    "                        log_str = '%s %s,' % (log_str, close_word)\n",
    "                    #print(log_str)\n",
    "                    #print(\"\\n\")\n",
    "            final_embeddings = normalized_embeddings.eval()\n",
    "            #Write corresponding labels for the embeddings\n",
    "            with open(log_dir + '/metadata.tsv', 'w') as f:\n",
    "                for i in range(len(dic)): \n",
    "                    f.write(rev_dic[i] + '\\n')\n",
    "            # Save the model for chpts \n",
    "            saver.save(session, os.path.join(log_dir, 'model.ckpt'))\n",
    "            # Create a configuration for visualizing embeddings with the labels in\n",
    "            # TensorBoard.\n",
    "            config = projector.ProjectorConfig()\n",
    "            embedding_conf = config.embeddings.add()\n",
    "            embedding_conf.tensor_name = embeddings.name\n",
    "            embedding_conf.metadata_path = os.path.join(log_dir, 'metadata.tsv')\n",
    "            projector.visualize_embeddings(writer, config)\n",
    "        writer.close()\n",
    "        return avg_loss_list, steps_list\n",
    "# #         Step 6: Visualize the embeddings.\n",
    "# #         pylint: disable=missing-docstring\n",
    "# #         Function to draw visualization of distance between embeddings.\n",
    "# #         def plot_with_labels(low_dim_embs, labels, filename):\n",
    "#             assert low_dim_embs.shape[0] >= len(labels), 'More labels than embeddings'\n",
    "#             plt.figure(figsize=(18, 18))  # in inches\n",
    "#             for i, label in enumerate(labels):\n",
    "#                 x, y = low_dim_embs[i, :]\n",
    "#                 plt.scatter(x, y)\n",
    "#                 plt.annotate(\n",
    "#                     label,\n",
    "#                     xy=(x, y),\n",
    "#                     xytext=(5, 2),\n",
    "#                     textcoords='offset points',\n",
    "#                     ha='right',\n",
    "#                     va='bottom')\n",
    "#                 plt.savefig(filename)\n",
    "#         try:\n",
    "#             # pylint: disable=g-import-not-at-top\n",
    "#             from sklearn.manifold import TSNE\n",
    "#             import matplotlib.pyplot as plt\n",
    "#             tsne = TSNE(\n",
    "#                 perplexity=30, n_components=2, init='pca', n_iter=5000, method='exact')\n",
    "#             plot_only = 500\n",
    "#             low_dim_embs = tsne.fit_transform(final_embeddings[:plot_only, :])\n",
    "#             labels = [rev_dic[i] for i in range(plot_only)]\n",
    "#             plot_with_labels(low_dim_embs, labels, os.path.join(gettempdir(), 'tsne.png'))\n",
    "#         except ImportError as ex:\n",
    "#             print('Please install sklearn, matplotlib, and scipy to show embeddings.')\n",
    "#             print(ex)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576 INS_SingleVariableDeclaration_MethodDeclaration -> 484 INS_ImportDeclaration_CompilationUnit\n",
      "576 INS_SingleVariableDeclaration_MethodDeclaration -> 576 INS_SingleVariableDeclaration_MethodDeclaration\n",
      "576 INS_SingleVariableDeclaration_MethodDeclaration -> 576 INS_SingleVariableDeclaration_MethodDeclaration\n",
      "576 INS_SingleVariableDeclaration_MethodDeclaration -> 213 INS_TagElement_Javadoc\n",
      "213 INS_TagElement_Javadoc -> 213 INS_TagElement_Javadoc\n",
      "213 INS_TagElement_Javadoc -> 576 INS_SingleVariableDeclaration_MethodDeclaration\n",
      "213 INS_TagElement_Javadoc -> 576 INS_SingleVariableDeclaration_MethodDeclaration\n",
      "213 INS_TagElement_Javadoc -> 213 INS_TagElement_Javadoc\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow._api.v1.compat' has no attribute 'v2'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-5b82b68212c7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'__main__'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m     \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\ichel\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\platform\\app.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(main, argv)\u001b[0m\n\u001b[0;32m    123\u001b[0m   \u001b[1;31m# Call the main function, passing through any arguments\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    124\u001b[0m   \u001b[1;31m# to the final program.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 125\u001b[1;33m   \u001b[0m_sys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    126\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-9-5b82b68212c7>\u001b[0m in \u001b[0;36mmain\u001b[1;34m(unused_argv)\u001b[0m\n\u001b[0;32m     14\u001b[0m         help='The log directory for TensorBoard summaries.')\n\u001b[0;32m     15\u001b[0m     \u001b[0mflags\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0munused_flags\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparse_known_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m     \u001b[0mavg_loss_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msteps_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mword2vec_basic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mflags\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdic\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfreq_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mavg_loss_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msteps_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-8-1d84865906ea>\u001b[0m in \u001b[0;36mword2vec_basic\u001b[1;34m(log_dir, dic, freq_dict, training_data)\u001b[0m\n\u001b[0;32m    142\u001b[0m     \u001b[0mnum_steps\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m10000\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    143\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 144\u001b[1;33m     \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    145\u001b[0m         \u001b[1;31m#open a writer to write summaries\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    146\u001b[0m         \u001b[0mwriter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFileWriter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlog_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'tensorflow._api.v1.compat' has no attribute 'v2'"
     ]
    }
   ],
   "source": [
    "# All functionality is run after tf.compat.v1.app.run() (b/122547914). This\n",
    "# could be split up but the methods are laid sequentially with their usage for\n",
    "# clarity.\n",
    "def main(unused_argv):\n",
    "  # Give a folder path as an argument with '--log_dir' to save\n",
    "  # TensorBoard summaries. Default is a log folder in current directory.\n",
    "    current_path = os.path.dirname(os.path.realpath(sys.argv[0]))\n",
    "\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\n",
    "        '--log_dir',\n",
    "        type=str,\n",
    "        default=os.path.join(current_path, 'log'),\n",
    "        help='The log directory for TensorBoard summaries.')\n",
    "    flags, unused_flags = parser.parse_known_args()\n",
    "    avg_loss_list, steps_list = word2vec_basic(flags.log_dir, dic, freq_dict, training_data)\n",
    "    plt.figure(figsize=(20, 20))\n",
    "    plt.plot(avg_loss_list, steps_list)\n",
    "    plt.title(\"Avg Loss\")\n",
    "    plt.xlabel(\"epochs\")\n",
    "    plt.ylabel(\"loss\")\n",
    "    plt.show()\n",
    "if __name__ == '__main__':\n",
    "    tf.app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 401012323037476815\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 6672343368\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 11150605529491726294\n",
      "physical_device_desc: \"device: 0, name: GeForce GTX 1080, pci bus id: 0000:0a:00.0, compute capability: 6.1\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

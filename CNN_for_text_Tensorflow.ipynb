{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-21T03:27:43.628313Z",
     "start_time": "2019-07-21T03:27:34.819524Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras import optimizers\n",
    "\n",
    "\n",
    "import sys\n",
    "from collections import Counter \n",
    "import pprint \n",
    "import math\n",
    "import argparse \n",
    "import os\n",
    "import collections\n",
    "import json\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import random\n",
    "import time \n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-21T03:27:46.300541Z",
     "start_time": "2019-07-21T03:27:43.631478Z"
    }
   },
   "outputs": [],
   "source": [
    "def parse_json(filepath):\n",
    "    \"\"\"\n",
    "    function used to parse json of each commit json file\n",
    "\n",
    "    Args:\n",
    "        filepath_list - list of filepaths\n",
    "\n",
    "    Returns:\n",
    "        files_json - list object contains parsed information\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    files_json = []\n",
    "    commit_ids = []\n",
    "    # each commits\n",
    "    files = os.listdir(filepath)\n",
    "    for path in files:\n",
    "        commit_id = path.split(\"_\")[1].split(\".\")[0]\n",
    "        if os.stat(filepath + path).st_size != 0 and path != 'desktop.ini':\n",
    "            with open(filepath + path, encoding=\"utf8\") as f:\n",
    "                data = json.load(f)\n",
    "                files_list = []\n",
    "                # each file in commits\n",
    "                for file in data['files']:\n",
    "                    # parse only cluster file\n",
    "                    for key in file.keys():\n",
    "                        if re.match('^.*_cluster$', key):\n",
    "                            actions_list = []\n",
    "                            actions = file[key]['actions']\n",
    "                            # each action in file\n",
    "                            for action in actions:\n",
    "                                actions_list.append(action['root'])\n",
    "                            files_list.append(actions_list)\n",
    "            if len(files_list) != 0:\n",
    "                files_json.append(files_list)\n",
    "                commit_ids.append(commit_id)\n",
    "    assert(len(commit_ids) == len(files_json))      \n",
    "    # return\n",
    "    return files_json, commit_ids\n",
    "\n",
    "\n",
    "folder_path = 'C:\\\\Users\\\\ichel\\\\Desktop\\\\tmp_JSON_labeled_commits\\\\'\n",
    "all_files, csha = parse_json(folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-21T03:27:46.324762Z",
     "start_time": "2019-07-21T03:27:46.305599Z"
    }
   },
   "outputs": [],
   "source": [
    "def preprocess_roots(files_data):\n",
    "    counting = {}\n",
    "    for file_index, files in enumerate(files_data):\n",
    "        for root_index, roots in enumerate(files):\n",
    "            for action_index, actions in enumerate(roots):\n",
    "                temp = actions.split(' at ')[0].strip()\n",
    "                tempq = []\n",
    "                if temp.startswith('INS'):\n",
    "                    tempq.append('INS')\n",
    "                    words = [temp.split('INS ')[1].split('to ')[0].strip()\n",
    "                             ] + [temp.split('INS ')[1].split('to ')[-1].strip()]\n",
    "                    for items in words:\n",
    "\n",
    "                        items = items.split(': ')[0].strip()\n",
    "                        tempq.append(items)\n",
    "                    temp = '_'.join(tempq)\n",
    "\n",
    "                if temp.startswith('UPDATE'):\n",
    "                    temp = 'UPDATE'\n",
    "                if temp.startswith('MOVE'):\n",
    "                    temp2 = temp.split(' from ')[1].strip()\n",
    "                    tempq.append('MOVE')\n",
    "                    tempq.append(temp2.split(': ')[0].strip())\n",
    "                    temp = '_'.join(tempq)\n",
    "\n",
    "                if temp.startswith('DEL'):\n",
    "                    tempq.append('DEL')\n",
    "                    tempq.append(temp.split('DEL ')[1].split(': ')[0].strip())\n",
    "                    temp = '_'.join(tempq)\n",
    "                temp = temp.replace(\" \", \"_\")\n",
    "                counting[temp] = counting.get(temp, 0) + 1\n",
    "                files_data[file_index][root_index][action_index] = temp\n",
    "    dic = {}\n",
    "    i = 0\n",
    "    for k, v in counting.items():\n",
    "        dic[k] = i  \n",
    "        i += 1\n",
    "    return dic, files_data, counting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-21T03:27:46.475539Z",
     "start_time": "2019-07-21T03:27:46.328083Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "444\n"
     ]
    }
   ],
   "source": [
    "dic, datas, freq_dict = preprocess_roots(all_files)\n",
    "rev_dic = dict(zip(dic.values(), dic.keys()))\n",
    "print(len(dic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-21T03:27:46.488683Z",
     "start_time": "2019-07-21T03:27:46.478368Z"
    }
   },
   "outputs": [],
   "source": [
    "def actions2sentence(datas):\n",
    "    data_total = []\n",
    "    for files in datas:\n",
    "        data4file = []\n",
    "        for roots in files:\n",
    "            sentence = ' '.join(roots)\n",
    "            data4file.append(sentence)\n",
    "        data_total.append(data4file)\n",
    "    return data_total\n",
    "\n",
    "\n",
    "training_data = actions2sentence(datas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_index_strange_words(training_data):\n",
    "    for i, item in enumerate(training_data):\n",
    "        for j, file in enumerate(item):\n",
    "            for k, action in enumerate(file.split()):\n",
    "                index = dic.get(action)\n",
    "                if index is None: # for debug \n",
    "                    print(\"==============================\")\n",
    "                    print(action) # for debug \n",
    "                    print('commits index: %d'%i)\n",
    "                    print('file: %d'%j)\n",
    "                    print('action: %d'%k)\n",
    "check_index_strange_words(training_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Permute Order of File \n",
    "**Purpose**: Here we permutate the order of files within a given commit while still maintaining the labels for that commit. \n",
    "This helps our CNN by: \n",
    "- 1) Increasing the training samples \n",
    "- 2) Make the CNN invariant to file location "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop labels\n",
    "def drop_labels(df, labels):\n",
    "    \"\"\"\n",
    "    Drop some of labels\n",
    "\n",
    "    Args:\n",
    "    df - Dataframs\n",
    "    labels - List of labels name to drop\n",
    "\n",
    "    Returns:\n",
    "    new_df -  new dataframe\n",
    "    \"\"\"\n",
    "    # remove labels in categories list\n",
    "    new_df = df.copy()\n",
    "    new_df['categories'] = new_df['categories'].apply(lambda row: [item for item in row if item not in labels])\n",
    "\n",
    "    # remove columns\n",
    "    new_df = new_df.drop(labels, axis=1)\n",
    "\n",
    "    # remove columns which have no labels after removing labels\n",
    "    new_df['number_of_labels'] = new_df['categories'].apply(lambda row: len(row))\n",
    "    new_df = new_df[new_df['number_of_labels'] != 0].reset_index(drop=True)\n",
    "    new_df = new_df.drop(['number_of_labels'], axis=1)\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1922, 28)\n",
      "<class 'list'>\n",
      "['Testing', 'Bug fix']\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "# new = list(itertools.permutations([1, 2, 3]))   0: perm1, perm2, permutation3 \n",
    "# list_new = []\n",
    "# for ii in new:\n",
    "#     list_new.append(list(ii))\n",
    "    \n",
    "# for ii in list_new: \n",
    "#     print(type(ii))\n",
    "\n",
    "commits_dic = dict()\n",
    "for sha, training_file in zip(csha, training_data): \n",
    "    commits_dic[sha] = []\n",
    "    if len(training_file) <= 6: \n",
    "        tmp_permutate = list(itertools.permutations(training_file))\n",
    "        for permutated_file in tmp_permutate: \n",
    "            commits_dic[sha].append(list(permutated_file))\n",
    "    else: \n",
    "        commits_dic[sha].append(training_file)\n",
    "commits_df = pd.DataFrame(commits_dic.items())\n",
    "commits_df.columns = [\"Commit ID\", \"Files\"]\n",
    "\n",
    "df_new = pd.read_csv('C:\\\\Users\\\\ichel\\\\Desktop\\\\commit_data_new.csv')\n",
    "print(df_new.shape)\n",
    "\n",
    "# convert string to list\n",
    "from ast import literal_eval\n",
    "\n",
    "df_new['categories'] = df_new['categories'].apply(lambda x: literal_eval(x))\n",
    "print(type(df_new['categories'].values[0]))\n",
    "print(df_new['categories'].values[0])\n",
    "df_new = df_new.drop(['Unnamed: 0'], axis = 1)\n",
    "commits_labels_df = pd.merge(commits_df, df_new, on='Commit ID')\n",
    "commits_labels_df.head(1)\n",
    "s= commits_labels_df.apply(lambda x: pd.Series(x['Files']),axis=1).stack().reset_index(level=1, drop=True)\n",
    "s.name = \"Files\"\n",
    "commits_labels_df = commits_labels_df.drop(\"Files\", axis=1) \n",
    "commits_labels_df = commits_labels_df.join(s)\n",
    "commits_labels_df = drop_labels(commits_labels_df, [\"Testing\", \"Build\", \"Versioning\", \"Indentation\", \"Internationalization\", \"Merge\", \\\n",
    "                                                   \"Module Move\", \"Module Remove\"])\n",
    "commits_labels_df.shape\n",
    "commit_files = commits_labels_df[\"Files\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-21T03:27:46.502749Z",
     "start_time": "2019-07-21T03:27:46.491433Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INS_ImportDeclaration_CompilationUnit INS_MethodDeclaration_TypeDeclaration INS_ImportDeclaration_CompilationUnit INS_ImportDeclaration_CompilationUnit INS_VariableDeclarationStatement_Block INS_IfStatement_Block INS_IfStatement_Block INS_ExpressionStatement_Block UPDATE MOVE_Block UPDATE UPDATE UPDATE UPDATE INS_MethodInvocation_MethodInvocation MOVE_MethodInvocation\n"
     ]
    }
   ],
   "source": [
    "def concat_files_to_sentence(training_data): \n",
    "    concat_data = \"\"\n",
    "    tmp_list = []\n",
    "    for items in training_data:\n",
    "        concat_data = \" \".join(items)\n",
    "        tmp_list.append(concat_data)\n",
    "        \n",
    "    return tmp_list\n",
    "concat_train_data = concat_files_to_sentence(commit_files)\n",
    "print(concat_train_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-21T03:27:53.112668Z",
     "start_time": "2019-07-21T03:27:46.510367Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<sample training data>:  ['UPDATE UPDATE']\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def get_seqlength(training_data):\n",
    "    max_root_len = 0\n",
    "    seqlength_list = []\n",
    "    for item in training_data:\n",
    "        seqlength_list.append(len(item.split()))\n",
    "        if len(item.split()) >  max_root_len: \n",
    "            max_root_len = len(item.split())\n",
    "    return max_root_len, seqlength_list\n",
    "\n",
    "def plot_hist(seqlength_list): \n",
    "    plt.figure(figsize=(20,10))\n",
    "    number_of_files = np.array(seqlength_list)\n",
    "    bincount = np.bincount(seqlength_list)\n",
    "    x = np.arange(1, len(bincount)+1)\n",
    "    n, bins, patches = plt.hist(seqlength_list,x)\n",
    "\n",
    "max_seqlength, sequence_list = get_seqlength(concat_train_data)\n",
    "print(\"<sample training data>: \", training_data[0])\n",
    "plot_hist(sequence_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-21T03:27:53.136546Z",
     "start_time": "2019-07-21T03:27:53.117407Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143\n"
     ]
    }
   ],
   "source": [
    "# getting file threshold\n",
    "threshold = 0.95\n",
    "number_of_actions = [len(item.split()) for item in concat_train_data]\n",
    "\n",
    "def get_file_threshold(number_of_files, threshold = 0.95):\n",
    "    '''\n",
    "    get padding threshold for files dimension\n",
    "    \n",
    "    Args:\n",
    "        number_of_files - array of the number of files in each commits\n",
    "        threshold - drop all commits with its the number of files beyond this threshold\n",
    "    Returns:\n",
    "        padding threshold - number\n",
    "    '''\n",
    "    \n",
    "    total_files = len(number_of_files)\n",
    "    number_of_files = np.array(number_of_files)\n",
    "    bincount = np.bincount(number_of_files)\n",
    "\n",
    "    sum_file = 0\n",
    "    for index, item in enumerate(bincount):\n",
    "        sum_file += item\n",
    "        #print(index,item)\n",
    "        #print(sum_file)\n",
    "        if sum_file > threshold*total_files:\n",
    "            padding_files_threshold = index\n",
    "            break\n",
    "            \n",
    "    return padding_files_threshold\n",
    "\n",
    "length_threshold = get_file_threshold(number_of_actions, threshold)\n",
    "print(length_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "commits_labels_df[\"Files\"] = concat_train_data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-21T03:27:53.530703Z",
     "start_time": "2019-07-21T03:27:53.490766Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21128, 21)\n"
     ]
    }
   ],
   "source": [
    "commits_labels_df['len_seq'] = commits_labels_df.apply(lambda row: len(row['Files'].split()), axis = 1)\n",
    "commits_labels_df = commits_labels_df[commits_labels_df['len_seq'] <= length_threshold].reset_index(drop = True)\n",
    "print(commits_labels_df.shape)  #### (21128, 21) :Here "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-21T03:27:53.945727Z",
     "start_time": "2019-07-21T03:27:53.533255Z"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'utils'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-3bb14a5c6e2f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle_labels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_tag_counts_and_labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle_labels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrop_labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle_labels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgroup_labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle_labels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcategories_count\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle_labels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_imbalance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'utils'"
     ]
    }
   ],
   "source": [
    "from utils.handle_labels import get_tag_counts_and_labels\n",
    "from utils.handle_labels import drop_labels\n",
    "from utils.handle_labels import group_labels\n",
    "from utils.handle_labels import categories_count\n",
    "from utils.handle_labels import get_imbalance\n",
    "from utils.handle_labels import label_distribution\n",
    "from utils.handle_labels import number_of_labels\n",
    "from utils.message_preprocess import message_processing\n",
    "# plot untils funcion\n",
    "from utils.plot_utils import pie_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-21T03:27:53.952549Z",
     "start_time": "2019-07-21T03:27:45.231Z"
    }
   },
   "outputs": [],
   "source": [
    "df_new = pd.read_csv('data/commit_data_new.csv')\n",
    "print(df_new.shape)\n",
    "\n",
    "# convert string to list\n",
    "from ast import literal_eval\n",
    "\n",
    "df_new['categories'] = df_new['categories'].apply(lambda x: literal_eval(x))\n",
    "print(type(df_new['categories'].values[0]))\n",
    "print(df_new['categories'].values[0])\n",
    "df_new = df_new.drop(['Unnamed: 0'], axis = 1)\n",
    "df_new = drop_labels(df_new, ['Testing', 'Build'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-21T03:27:53.953638Z",
     "start_time": "2019-07-21T03:27:45.457Z"
    }
   },
   "outputs": [],
   "source": [
    "df.columns = ['Commit ID','sequence', 'len_seq']\n",
    "result = pd.merge(df, df_new, on='Commit ID')\n",
    "result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-21T03:27:53.957499Z",
     "start_time": "2019-07-21T03:27:46.154Z"
    }
   },
   "outputs": [],
   "source": [
    "_ , target_col = get_tag_counts_and_labels(result)\n",
    "output_dim = len(target_col)\n",
    "print(output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-21T03:27:53.959135Z",
     "start_time": "2019-07-21T03:27:46.918Z"
    }
   },
   "outputs": [],
   "source": [
    "target_col = ['Maintenance']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-21T03:27:53.960319Z",
     "start_time": "2019-07-21T03:27:47.213Z"
    }
   },
   "outputs": [],
   "source": [
    "y = result[target_col].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-21T03:27:53.961836Z",
     "start_time": "2019-07-21T03:27:47.412Z"
    }
   },
   "outputs": [],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-21T03:27:53.966249Z",
     "start_time": "2019-07-21T03:27:47.781Z"
    }
   },
   "outputs": [],
   "source": [
    "docs = result['sequence'].values\n",
    "t = Tokenizer(filters = '')\n",
    "t.fit_on_texts(docs)\n",
    "sequences = t.texts_to_sequences(docs)\n",
    "print(sequences[0])\n",
    "padded_seq = pad_sequences(sequences, maxlen=length_threshold, padding=\"post\", truncating=\"post\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-21T03:27:53.968217Z",
     "start_time": "2019-07-21T03:27:48.097Z"
    }
   },
   "outputs": [],
   "source": [
    "vocabulary = t.word_index\n",
    "vocabulary_inv = dict((v, k) for k, v in vocabulary.items())\n",
    "vocabulary_inv[0] = \"<PAD/>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-21T03:27:53.969406Z",
     "start_time": "2019-07-21T03:27:48.398Z"
    }
   },
   "outputs": [],
   "source": [
    "X = padded_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-21T03:27:53.970054Z",
     "start_time": "2019-07-21T03:27:48.654Z"
    }
   },
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-21T03:27:53.970717Z",
     "start_time": "2019-07-21T03:27:48.859Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state = 0, shuffle = True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-21T03:27:53.972439Z",
     "start_time": "2019-07-21T03:27:49.033Z"
    }
   },
   "outputs": [],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-21T03:27:53.974305Z",
     "start_time": "2019-07-21T03:27:49.712Z"
    }
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from gensim.models import word2vec\n",
    "from os.path import join, exists, split\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-21T03:27:53.975637Z",
     "start_time": "2019-07-21T03:27:49.906Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_word2vec(sentence_matrix, vocabulary_inv,\n",
    "                   num_features=300, min_word_count=1, context=10):\n",
    "    \"\"\"\n",
    "    Trains, saves, loads Word2Vec model\n",
    "    Returns initial weights for embedding layer.\n",
    "   \n",
    "    inputs:\n",
    "    sentence_matrix # int matrix: num_sentences x max_sentence_len\n",
    "    vocabulary_inv  # dict {int: str}\n",
    "    num_features    # Word vector dimensionality                      \n",
    "    min_word_count  # Minimum word count                        \n",
    "    context         # Context window size \n",
    "    \"\"\"\n",
    "    model_dir = 'models'\n",
    "    model_name = \"{:d}features_{:d}minwords_{:d}context\".format(num_features, min_word_count, context)\n",
    "    model_name = join(model_dir, model_name)\n",
    "    if exists(model_name):\n",
    "        embedding_model = word2vec.Word2Vec.load(model_name)\n",
    "        print('Load existing Word2Vec model \\'%s\\'' % split(model_name)[-1])\n",
    "    else:\n",
    "        # Set values for various parameters\n",
    "        num_workers = 2  # Number of threads to run in parallel\n",
    "        downsampling = 1e-3  # Downsample setting for frequent words\n",
    "\n",
    "        # Initialize and train the model\n",
    "        print('Training Word2Vec model...')\n",
    "        sentences = [[vocabulary_inv[w] for w in s] for s in sentence_matrix]\n",
    "        embedding_model = word2vec.Word2Vec(sentences, workers=num_workers,\n",
    "                                            size=num_features, min_count=min_word_count,\n",
    "                                            window=context, sample=downsampling)\n",
    "\n",
    "        # If we don't plan to train the model any further, calling \n",
    "        # init_sims will make the model much more memory-efficient.\n",
    "        embedding_model.init_sims(replace=True)\n",
    "\n",
    "        # Saving the model for later use. You can load it later using Word2Vec.load()\n",
    "        if not exists(model_dir):\n",
    "            os.mkdir(model_dir)\n",
    "        print('Saving Word2Vec model \\'%s\\'' % split(model_name)[-1])\n",
    "        embedding_model.save(model_name)\n",
    "\n",
    "    # add unknown words\n",
    "    embedding_weights = {key: embedding_model[word] if word in embedding_model else\n",
    "                              np.random.uniform(-0.25, 0.25, embedding_model.vector_size)\n",
    "                         for key, word in vocabulary_inv.items()}\n",
    "    return embedding_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-21T03:27:53.977924Z",
     "start_time": "2019-07-21T03:27:50.069Z"
    }
   },
   "outputs": [],
   "source": [
    "embedding_dim = 300\n",
    "min_word_count = 1\n",
    "context = 5\n",
    "embedding_weights = train_word2vec(padded_seq, vocabulary_inv, num_features=embedding_dim,\n",
    "                                       min_word_count=min_word_count, context=context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-21T03:27:53.979720Z",
     "start_time": "2019-07-21T03:27:50.237Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train = np.stack([np.stack([embedding_weights[word] for word in sentence]) for sentence in X_train])\n",
    "X_test = np.stack([np.stack([embedding_weights[word] for word in sentence]) for sentence in X_test])\n",
    "print(\"x_train static shape:\", X_train.shape)\n",
    "print(\"x_test static shape:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN for text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-21T03:27:53.982096Z",
     "start_time": "2019-07-21T03:27:50.555Z"
    }
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Flatten, Input, MaxPooling1D, Convolution1D, Embedding\n",
    "from keras.layers.merge import Concatenate\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-21T03:27:53.985666Z",
     "start_time": "2019-07-21T03:27:50.725Z"
    }
   },
   "outputs": [],
   "source": [
    "# Model type. See Kim Yoon's Convolutional Neural Networks for Sentence Classification, Section 3\n",
    "model_type = \"CNN-non-static\"  # CNN-rand|CNN-non-static|CNN-static\n",
    "\n",
    "# Model Hyperparameters\n",
    "embedding_dim = 300\n",
    "filter_sizes = (5, 10)\n",
    "num_filters = 10\n",
    "dropout_prob = (0.5, 0.5)\n",
    "hidden_dims = 50\n",
    "\n",
    "# Training parameters\n",
    "batch_size = 8\n",
    "num_epochs = 50\n",
    "\n",
    "sequence_length = length_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-21T03:27:53.987127Z",
     "start_time": "2019-07-21T03:27:50.921Z"
    }
   },
   "outputs": [],
   "source": [
    "# input\n",
    "input_shape = (sequence_length, embedding_dim)\n",
    "model_input = Input(shape=input_shape)\n",
    "\n",
    "z = model_input\n",
    "\n",
    "# dropout layer\n",
    "z = Dropout(dropout_prob[0])(z)\n",
    "\n",
    "# Convolutional block\n",
    "conv_blocks = []\n",
    "for sz in filter_sizes:\n",
    "    conv = Convolution1D(filters=num_filters,\n",
    "                         kernel_size=sz,\n",
    "                         padding=\"valid\",\n",
    "                         activation=\"relu\",\n",
    "                         strides=1)(z)\n",
    "    conv = MaxPooling1D(pool_size=2)(conv)\n",
    "    conv = Flatten()(conv)\n",
    "    conv_blocks.append(conv)\n",
    "\n",
    "z = Concatenate()(conv_blocks) if len(conv_blocks) > 1 else conv_blocks[0]\n",
    "\n",
    "z = Dropout(dropout_prob[1])(z)\n",
    "z = Dense(hidden_dims, activation=\"relu\")(z)\n",
    "\n",
    "model_output = Dense(1, activation=\"sigmoid\")(z)\n",
    "\n",
    "model = Model(model_input, model_output)\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer= optimizers.SGD(lr=0.001, decay=1e-6, momentum=0.9, nesterov=True), \n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-21T03:27:53.987918Z",
     "start_time": "2019-07-21T03:27:51.138Z"
    }
   },
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train, batch_size=batch_size, epochs=num_epochs,\n",
    "          validation_data=(X_test, y_test), verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-21T03:27:53.989615Z",
     "start_time": "2019-07-21T03:27:51.341Z"
    }
   },
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "\n",
    "y_pred_bool = (y_pred > 0.5)\n",
    "\n",
    "predictions = y_pred_bool.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-21T03:27:53.991344Z",
     "start_time": "2019-07-21T03:27:51.561Z"
    }
   },
   "outputs": [],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-21T03:27:53.992898Z",
     "start_time": "2019-07-21T03:27:51.761Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import hamming_loss\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score \n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "def print_evaluation_scores(y_test, predicted):\n",
    "    \n",
    "    print('Accuracy:', accuracy_score(y_test, predicted))\n",
    "    print('F1-score macro:', f1_score(y_test, predicted, average='macro'))\n",
    "    print('F1-score micro:', f1_score(y_test, predicted, average='micro'))\n",
    "    print('F1-score weighted:', f1_score(y_test, predicted, average='weighted'))\n",
    "    print('Hamming_loss:', hamming_loss(y_test, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-21T03:27:53.994119Z",
     "start_time": "2019-07-21T03:27:52.337Z"
    }
   },
   "outputs": [],
   "source": [
    "print_evaluation_scores(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

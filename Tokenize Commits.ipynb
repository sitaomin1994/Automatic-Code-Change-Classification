{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-15T04:35:48.648900Z",
     "start_time": "2019-07-15T04:35:48.038717Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from os import listdir\n",
    "from os import path\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "# % matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-15T04:35:48.653927Z",
     "start_time": "2019-07-15T04:35:48.650804Z"
    }
   },
   "outputs": [],
   "source": [
    "# i = 0\n",
    "# for path in listdir('../data/tmp_JSON_labeled_commits/'):\n",
    "#     print(i,path)\n",
    "#     i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  file threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-15T04:35:49.185216Z",
     "start_time": "2019-07-15T04:35:48.658435Z"
    }
   },
   "outputs": [],
   "source": [
    "# parse json to files and actions\n",
    "\n",
    "def parse_json(filepath_list):\n",
    "    '''\n",
    "    function used to parse json of each commit json file\n",
    "    \n",
    "    Args:\n",
    "        filepath_list - list of filepaths\n",
    "    \n",
    "    Returns:\n",
    "        files_json - list object contains parsed information\n",
    "    \n",
    "    '''\n",
    "    number_of_files = []\n",
    "    files_json = []\n",
    "    \n",
    "    # each commits\n",
    "    for path in filepath_list:\n",
    "        with open(path,'rb') as f:\n",
    "            data = json.load(f)\n",
    "            files_list = []\n",
    "            # each file in commits\n",
    "            for file in data['files']:\n",
    "                # parse only cluster file\n",
    "                for key in file.keys():\n",
    "                    if re.match('^.*_cluster$',key):\n",
    "                        actions_list = []\n",
    "                        actions = file[key]['actions']\n",
    "                        # each action in file\n",
    "                        for action in actions:\n",
    "                            actions_list.append(action['root'])\n",
    "                        files_list.append(actions_list)\n",
    "        \n",
    "        files_json.append(files_list)        \n",
    "    \n",
    "    # return\n",
    "    return files_json\n",
    "\n",
    "# get file path list\n",
    "filepath_list = ['../data/tmp_JSON_labeled_commits/' + path for path in listdir('../data/tmp_JSON_labeled_commits/')]\n",
    "files_json = parse_json(filepath_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-15T04:35:49.197572Z",
     "start_time": "2019-07-15T04:35:49.188263Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22\n"
     ]
    }
   ],
   "source": [
    "# getting file threshold\n",
    "threshold = 0.95\n",
    "number_of_files = [len(files) for files in files_json]\n",
    "\n",
    "def get_file_threshold(number_of_files, threshold = 0.95):\n",
    "    '''\n",
    "    get padding threshold for files dimension\n",
    "    \n",
    "    Args:\n",
    "        number_of_files - array of the number of files in each commits\n",
    "        threshold - drop all commits with its the number of files beyond this threshold\n",
    "    Returns:\n",
    "        padding threshold - number\n",
    "    '''\n",
    "    \n",
    "    total_files = len(number_of_files)\n",
    "    number_of_files = np.array(number_of_files)\n",
    "    bincount = np.bincount(number_of_files)\n",
    "\n",
    "    sum_file = 0\n",
    "    for index, item in enumerate(bincount):\n",
    "        sum_file += item\n",
    "        #print(index,item)\n",
    "        #print(sum_file)\n",
    "        if sum_file > threshold*total_files:\n",
    "            padding_files_threshold = index\n",
    "            break\n",
    "            \n",
    "    return padding_files_threshold\n",
    "\n",
    "file_threshold = get_file_threshold(number_of_files, threshold)\n",
    "print(file_threshold)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "plt.figure(figsize=(20,20))\n",
    "\n",
    "number_of_files = np.array(number_of_files)\n",
    "\n",
    "bincount = np.bincount(number_of_files)\n",
    "\n",
    "x = np.arange(1, len((bincount))+1)\n",
    "\n",
    "n, bins, patches = plt.hist(number_of_files,x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# root_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-15T04:35:49.205589Z",
     "start_time": "2019-07-15T04:35:49.199508Z"
    }
   },
   "outputs": [],
   "source": [
    "threshold = 0.95\n",
    "number_of_root = []\n",
    "root_count = []\n",
    "for files in files_json:\n",
    "    number_of_root.extend([len(roots) for roots in files])\n",
    "    root_count.append([len(roots) for roots in files])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-15T04:35:49.217276Z",
     "start_time": "2019-07-15T04:35:49.208238Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38\n"
     ]
    }
   ],
   "source": [
    "# getting root threshold\n",
    "\n",
    "def get_root_threshold(number_of_root, threshold = 0.95):\n",
    "    '''\n",
    "    get padding threshold for root dimension\n",
    "    \n",
    "    Args:\n",
    "        number_of_root - array of the number of root in each commits\n",
    "        threshold - drop all commits with its the number of roots beyond this threshold\n",
    "    Returns:\n",
    "        padding threshold - number\n",
    "    '''\n",
    "    \n",
    "    total_root = len(number_of_root)\n",
    "    number_of_root = np.array(number_of_root)\n",
    "    bincount = np.bincount(number_of_root)\n",
    "\n",
    "    sum_root = 0\n",
    "    for index, item in enumerate(bincount):\n",
    "        sum_root += item\n",
    "        #print(index,item)\n",
    "        #print(sum_file)\n",
    "        if sum_root > threshold*total_root:\n",
    "            padding_root_threshold = index\n",
    "            break\n",
    "            \n",
    "    return padding_root_threshold\n",
    "\n",
    "root_threshold = get_root_threshold(number_of_root, threshold)\n",
    "print(root_threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# select files which comply with the standard  \n",
    "[roots number $\\le$ 8, files number $\\le$ 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-15T04:35:49.226079Z",
     "start_time": "2019-07-15T04:35:49.220395Z"
    }
   },
   "outputs": [],
   "source": [
    "file_threshold = 5\n",
    "root_threshold = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-15T04:35:49.237481Z",
     "start_time": "2019-07-15T04:35:49.229342Z"
    }
   },
   "outputs": [],
   "source": [
    "cmt_used = []  # index of commits which comply with the standard.\n",
    "i = 0\n",
    "for counts in root_count:\n",
    "    if (number_of_files[i] <= file_threshold) and (False not in [\n",
    "            items <= root_threshold for items in counts\n",
    "    ]):\n",
    "        cmt_used.append(i)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-15T04:35:49.244648Z",
     "start_time": "2019-07-15T04:35:49.240818Z"
    }
   },
   "outputs": [],
   "source": [
    "# cmt_used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-15T04:35:49.249945Z",
     "start_time": "2019-07-15T04:35:49.246115Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We will use 487 commits while the total number of commits is 918\n"
     ]
    }
   ],
   "source": [
    "print(\"We will use {} commits while the total number of commits is {}\".format(\n",
    "    len(cmt_used), len(files_json)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Data preparation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-15T04:35:49.298920Z",
     "start_time": "2019-07-15T04:35:49.252389Z"
    }
   },
   "outputs": [],
   "source": [
    "path = []\n",
    "for index in cmt_used:\n",
    "    path.append(filepath_list[index])\n",
    "files_data = parse_json(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-15T04:35:49.322733Z",
     "start_time": "2019-07-15T04:35:49.300808Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "first_word = {}\n",
    "counting = {}\n",
    "counting_ins = {}\n",
    "counting_update = {}\n",
    "counting_mov = {}\n",
    "counting_del = {}\n",
    "\n",
    "for file_index, files in enumerate(files_data):\n",
    "    #     print(\">>>\", file_index)\n",
    "    for root_index, roots in enumerate(files):\n",
    "        for action_index, actions in enumerate(roots):\n",
    "            temp = actions.split(' at ')[0]\n",
    "            first_word[temp.split()[0]] = first_word.get(temp.split()[0],\n",
    "                                                         0) + 1\n",
    "            tempq = []\n",
    "            #             print(file_index,temp)\n",
    "            if temp.startswith('INS'):\n",
    "#                 if file_index == 226:\n",
    "#                     print(temp)\n",
    "                tempq.append('INS')\n",
    "                words = [temp.split('INS ')[1].split(' to ')[0]\n",
    "                         ] + [temp.split('INS ')[1].split(' to ')[-1]]\n",
    "                for items in words:\n",
    "                    #                     print(items)\n",
    "#                     if file_index == 226:\n",
    "#                         print(tempq)\n",
    "                    items = items.split(': ')[0]\n",
    "                    tempq.append(items)\n",
    "                    counting_ins[items.strip()] = counting_ins.get(\n",
    "                        items.strip(), 0) + 1\n",
    "                    counting[items.strip()] = counting.get(items.strip(),\n",
    "                                                           0) + 1\n",
    "                temp = ' '.join(tempq)\n",
    "                if file_index == 226:\n",
    "                    print(tempq)\n",
    "                    print(temp)\n",
    "\n",
    "            if temp.startswith('UPDATE'):\n",
    "                temp = 'UPDATE'\n",
    "            if temp.startswith('MOVE'):\n",
    "                temp2 = temp.split(' from ')[1]\n",
    "                counting_mov[temp2.split(': ')[0]] = counting_mov.get(\n",
    "                    temp2.split(': ')[0], 0) + 1\n",
    "                counting[temp2.split(': ')[0]] = counting.get(\n",
    "                    temp2.split(': ')[0], 0) + 1\n",
    "                tempq.append('MOVE')\n",
    "                tempq.append(temp2.split(': ')[0])\n",
    "                temp = ' '.join(tempq)\n",
    "\n",
    "            if temp.startswith('DEL'):\n",
    "                #                 temp = temp\n",
    "                counting_del[temp.split('DEL ')[1].split(': ')\n",
    "                             [0]] = counting_del.get(\n",
    "                                 temp.split('DEL ')[1].split(': ')[0], 0) + 1\n",
    "                counting[temp.split('DEL ')[1].split(': ')[0]] = counting.get(\n",
    "                    temp.split('DEL ')[1].split(': ')[0], 0) + 1\n",
    "                tempq.append('DEL')\n",
    "                tempq.append(temp.split('DEL ')[1].split(': ')[0])\n",
    "                temp = ' '.join(tempq)\n",
    "#                 print(temp)\n",
    "\n",
    "            files_data[file_index][root_index][action_index] = temp\n",
    "            #             print(root_index, action_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-15T04:35:49.331164Z",
     "start_time": "2019-07-15T04:35:49.327002Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "b = []\n",
    "dic = {}\n",
    "i = 0\n",
    "for k,v in counting.items():\n",
    "    i += 1\n",
    "    b.append((v,k))\n",
    "    dic[k] = i # encode strats with 1, because 0 means no word\n",
    "b = sorted(b,reverse=True)\n",
    "i = 0\n",
    "for k,v in first_word.items():\n",
    "    i += 1\n",
    "    dic[k] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-15T04:35:49.347136Z",
     "start_time": "2019-07-15T04:35:49.333070Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "vec_ =np.zeros((len(files_data),root_threshold,3,file_threshold), dtype=int).tolist()\n",
    "for file_index, files in enumerate(files_data):\n",
    "    for root_index, roots in enumerate(files):\n",
    "        for action_index, actions in enumerate(roots):\n",
    "#             print(actions)\n",
    "            temp =np.zeros(3, dtype=int).tolist()\n",
    "            words = actions.split()\n",
    "#             print(words)\n",
    "            for index, word in enumerate(words):\n",
    "#                 temp[index] = dic[words]\n",
    "#                 print(file_index,root_index,index,action_index)\n",
    "                vec_[file_index][action_index][index][root_index] = dic[word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-15T04:35:49.364713Z",
     "start_time": "2019-07-15T04:35:49.351403Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(487, 8, 3, 5)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(vec_).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 487 is the numbers of commits\n",
    "* 8 is the numbers of roots in each file\n",
    "* 3 is one of the action\n",
    "* 5 is the numbers of files in each commit"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
